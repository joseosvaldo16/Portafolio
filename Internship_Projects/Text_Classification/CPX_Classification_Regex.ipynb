{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import required libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import openai\n",
    "import nltk\n",
    "import optuna\n",
    "import math\n",
    "import optuna\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "# NLTK packages for text preprocessing\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "##Scikit-learn packages for preprocessing, data cleaning, and other data preparation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import classification_report, accuracy_score , f1_score, log_loss\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "#Import XGBoost and Random Forest Classifer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Optuna packages for Hyperparameter optimization\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.pruners import HyperbandPruner\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "\n",
    "\n",
    "#Import tensorflow keras packages for deep learning models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LeakyReLU,Activation,BatchNormalization,GlobalMaxPooling1D,Conv1D,Reshape\n",
    "from keras.regularizers import l1_l2\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers.legacy import Adam\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "\n",
    "# Randomiztion control for tensorflow packages \n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create mapping for new categories\n",
    "#These categories where manually made but with help of kmeans clustering \n",
    "category_mapping = { \n",
    "\n",
    "    'display broken': 'display issue',\n",
    "    'broken display': 'display issue',\n",
    "    'display problem': 'display issue',\n",
    "    'fuzzy display': 'display issue',\n",
    "    'flashing display': 'display issue',\n",
    "    'display flipped': 'display issue',\n",
    "    'camera damaged': 'hardware issue',\n",
    "    'damage camera': 'hardware issue',\n",
    "    'cca changes' : 'testing issue',\n",
    "    'cca entry': 'testing issue',\n",
    "    'failing all batteries': 'battery issue',\n",
    "    'batteries drain quickly': 'battery issue',\n",
    "    'internal battery error': 'battery issue',\n",
    "    'leaking batteires':'battery issue',\n",
    "    'low battery message': 'battery issue',\n",
    "    'no voltage': 'power issue',\n",
    "    'unstable voltage' : 'power issue',\n",
    "    'no power on': 'power issue',\n",
    "    'charging problem' : 'power issue',\n",
    "    'printing issues': 'hardware issue',\n",
    "    'printer roller': 'hardware issue',\n",
    "    'out of paper': 'hardware issue',\n",
    "    'cable problems': 'cable issue',\n",
    "    'cables - melting': 'cable issue',\n",
    "    'only system tests': 'testing issue',\n",
    "    'no tes results': 'testing issue', \n",
    "    'will not test': 'testing issue',\n",
    "    'wrong sw': 'software issue',\n",
    "    'corrupted sw': 'software issue',\n",
    "    'over heating': 'fan issue',\n",
    "    'broken fan': 'fan issue',\n",
    "    'partial function': 'testing issue',\n",
    "    'en2 message': 'software issue',\n",
    "    'corrupted': 'software issue',\n",
    "    'date problems': 'software issue',\n",
    "    'usb port': 'hardware issue',\n",
    "    'mdx logo': 'freezes',\n",
    "    'lost pin': 'software issue',\n",
    "    'broken clamps': 'hardware issue',\n",
    "    'location id': 'bmis',\n",
    "    'button failed': 'hardware issue',\n",
    "    'damaged': 'hardware issue',\n",
    "    'auto testing': 'testing issue',\n",
    "    'cca issue': 'testing issue',\n",
    "    'reboots':'software issue',\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the origina CPX excel data\n",
    "original_df = pd.read_excel('CPX RMA analysis R2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy the columns of interest into a new dataframe and rename columns\n",
    "#This makes sure we have do not mutate the original data, rather we will be working with a copy\n",
    "\n",
    "clean_df = original_df[['Customer Reason', 'Complaint']].copy()\n",
    "clean_df.columns = ['Description','Category']\n",
    "clean_df['Description'] = clean_df['Description'] .astype(str) #Set datatype to string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for rows with empty values end drop\n",
    "clean_df.isna().any()\n",
    "clean_df = clean_df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply lowercasing to category column, then add New_Category column with the new mapped categories\n",
    "clean_df['Category'] = clean_df['Category'].str.lower()\n",
    "clean_df['New_Category'] = clean_df['Category'].replace(category_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get index of rows labled as 'multiple issues'\n",
    "multiple_issues_idx = clean_df.query(\"New_Category == 'multiple issues'\").index\n",
    "#Get only the rows whose category is not 'multiple issues' \n",
    "reduced_df = clean_df.query(\"New_Category != 'multiple issues'\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get list of new categories\n",
    "new_categories = reduced_df.New_Category.value_counts().index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text preprocessing\n",
    "\n",
    "Preprocessing for NLP is the process of cleaning and formatting raw text data before it's input to a machine learning model, which typically involves steps like tokenization, lowercasing, removing stop words, punctuation, and numbers, as well as stemming or lemmatization. This step is crucial as it transforms text into a form that can be represented as numerical features and understood by machine learning algorithms.Howerver, not all preprocessing steps are required for every natural language processing (NLP) task. The specific preprocessing steps one must choose to use will depend on the nature of the task, the specific requirements of your machine learning model, and the characteristics of the data. For that reason different preprocessing steps will be tried, tested, and evluated to see how different preprocessing steps affect the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(':', 3676), ('.', 2263), ('-', 1433), ('THE', 1415), ('#', 1371), ('TO', 1258), ('@', 1013), (',', 968), ('the', 764), ('AND', 638), ('UPDATE', 551), ('to', 534), ('SN', 528), ('NOT', 517), ('A', 461), ('IS', 427), ('WILL', 424), ('TOYOTA', 416), ('DLR', 414), ('PO', 357), ('and', 351), ('OF', 347), ('IT', 341), ('TESTER', 303), ('FOR', 303), ('ON', 299), ('*', 267), ('BAR', 265), (\"N'T\", 259), ('HE', 255), ('$', 251), ('is', 248), ('ISSUE', 245), ('UNIT', 242), ('I', 241), ('IN', 236), ('Toyota', 236), ('BATTERY', 226), ('TEST', 218), ('T', 200), ('CONNECT', 200), ('Contact', 198), ('unit', 195), ('S/N', 193), ('for', 190), ('REPAIR', 187), ('WIFI', 182), ('HAS', 181), ('WARRANTY', 179), ('KIT', 174), ('NISSAN', 174), ('WITH', 172), ('CUSTOMER', 168), ('EMAIL', 168), ('a', 162), ('BACK', 161), ('WAS', 161), ('it', 159), (')', 159), ('TOOL', 158), ('WHEN', 157), ('CPX-900P', 157), ('AN', 155), ('will', 153), ('(', 153), ('not', 151), ('BATTERIES', 149), ('RMA', 146), ('THAT', 145), ('PARTS', 143), ('SERVICE', 140), ('BUT', 138), ('in', 137), ('SAID', 133), ('AUTO', 133), ('SCREEN', 132), ('479', 129), ('on', 128), ('DEALER', 126), ('STORE', 125), ('PH', 125), ('THEY', 124), ('THIS', 123), ('CPX-900', 122), ('of', 122), ('Issue', 121), ('CABLES', 120), ('CONNECTED', 120), ('2', 117), ('TRIED', 114), ('The', 112), (\"'S\", 112), ('FROM', 109), ('Code', 109), ('you', 108), ('HAVE', 108), ('Email', 108), ('with', 106), ('NO', 106), ('FEE', 106)]\n"
     ]
    }
   ],
   "source": [
    "'''Tokenization is the process of breaking down text into individual words,\n",
    "phrases, symbols, or other meaningful elements, which are known as tokens.\n",
    "In the context of natural language processing (NLP), tokenization is typically\n",
    "the first step in preparing text data for analysis or machine learning.'''\n",
    "tokens = nltk.word_tokenize(' '.join(clean_df['Description']))\n",
    "\n",
    "# Count the occurrences of each token\n",
    "counter = Counter(tokens)\n",
    "\n",
    "# Find the most common tokens\n",
    "most_common_tokens = counter.most_common(100)  # Replace 20 with the number of tokens you want to find\n",
    "\n",
    "print(most_common_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the most frequently occurring tokens can assist us in identifying those that are irrelevant or constitute noise. If a token appears very frequently across the dataset, it may not be a good indicator of a specific class category. The underlying concept is that words with high variance across documents are often better predictors, as they can distinguish between different classes, while words with low variance, which appear uniformly across documents, provide less discriminative power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block performs several preprocessing steps on a given text. The function first converts the text to lowercase, then removes specific patterns and email addresses. If the openai_flag is not set, the function further cleans the text by removing punctuation, stop words, and numbers, and applies stemming to reduce words to their root form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for preprocessing text in a dataframe\n",
    "# The first 8 most commmon tokens are noise / irrelevant so we will remove them. \n",
    "\n",
    "ps = PorterStemmer()\n",
    "all_steps = False\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "      ps = PorterStemmer()\n",
    "      # Convert to lowercase\n",
    "      text = text.lower()\n",
    "\n",
    "      # Remove specific patterns\n",
    "      text = re.sub(r'[a-zA-Z0-9]*_x001e_([a-zA-Z0-9]*_)*', '', text)\n",
    "\n",
    "      text= text.replace(\"\\n\", \" \")\n",
    "    \n",
    "      # Remove email addresses\n",
    "      text = re.sub(r'\\S+@\\S+', '', text)\n",
    "            \n",
    "      if (all_steps):\n",
    "          # Remove punctuation\n",
    "          text = re.sub(r'[.:,@*$/#-]', ' ', text)\n",
    "          # Remove stop words\n",
    "          text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "          # Apply stemming\n",
    "          text = ' '.join(ps.stem(word) for word in text.split())\n",
    "          #Remove numbers\n",
    "          text = re.sub(r'\\d+', '', text)\n",
    "            \n",
    "          remove_words = ['toyota', 'sn', 'po','nissan','ph','p','n','email']\n",
    "          text = ' '.join([word for word in text.split() if word not in remove_words])\n",
    "\n",
    "      return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply processing and store restult in a new column\n",
    "all_steps = True\n",
    "reduced_df['Processed_Description_All'] = reduced_df['Description'].apply(preprocess_text)\n",
    "all_steps = False\n",
    "reduced_df['Processed_Description_Some'] = reduced_df['Description'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "burnsvil dlr koeun technic advisor burnsvil busi phone cpx tester current first one read batteri give warn clamp wrong termin switch clamp state clamp connect serial number one second broken posit clamp need new test cabl replac need sent also? serial number one let know next step\n",
      "burnsville toyota dlr#koeun technical advisor burnsville business phone: 952-435-8200 email:  have 2 cpx-900 testers that are currently down.  the first one will not read the battery and gives warning for the clamps being on the wrong terminals. if you switch clamps it states that there are no clamp connections.  serial number for that one is : the second has a broken positive clamp and needs a new test cable replacement. will this need to be sent in also? serial number for this one is : let me know what the next steps is.\n"
     ]
    }
   ],
   "source": [
    "#look a preprocessing results\n",
    "print(reduced_df['Processed_Description_All'].iloc[1])\n",
    "\n",
    "print(reduced_df['Processed_Description_Some'].iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Embeddings\n",
    "\n",
    "Main methods of text representation: Transformer-based models like GPT, Word2Vec, and TF-IDF.\n",
    "\n",
    "1. **Transformer-based models (like GPT)**: These models are based on the Transformer architecture, which was introduced in the paper \"Attention is All You Need\" by Vaswani et al. The key idea behind this architecture is the self-attention mechanism, which allows the model to weigh the importance of words in a sentence relative to each other. GPT (Generative Pretrained Transformer) is a specific implementation of this architecture that is trained to predict the next word in a sentence, given all the previous words. This allows it to learn a rich understanding of language, including grammar, semantics, and even some world knowledge. GPT and similar models are particularly good for tasks that require understanding of context, such as translation, summarization, and question answering.\n",
    "\n",
    "2. **Word2Vec**: This is a method for learning vector representations of words, introduced by Mikolov et al. at Google. It works by training a neural network to predict a word given its context (Continuous Bag of Words, CBOW) or to predict the context given a word (Skip-Gram). The learned word vectors capture many linguistic regularities and patterns; for example, vector('King') - vector('Man') + vector('Woman') roughly equals vector('Queen'). Word2Vec is useful for tasks that require understanding of word similarity and analogy, but it doesn't capture the context of a sentence as well as transformer models.\n",
    "\n",
    "3. **TF-IDF (Term Frequency-Inverse Document Frequency)**: This is a statistical method for representing text. It calculates the importance of a word in a document relative to a corpus, based on how often the word appears in the document (Term Frequency) and how rare the word is in the corpus (Inverse Document Frequency). TF-IDF is simple and efficient, and it's good for tasks like information retrieval and document classification where the exact wording isn't as important as the overall topic or theme. However, it doesn't capture the semantics of words or the structure of sentences.\n",
    "\n",
    "As for which one is better, it depends on the specific task:\n",
    "\n",
    "- If you need to understand the context of a sentence or generate human-like text, a transformer-based model like GPT would be the best choice.\n",
    "- If you're working with a task that requires understanding of word similarity and analogy, and less about the context or order of words, Word2Vec would be a good choice.\n",
    "- If you're trying to classify documents or retrieve information based on keywords, and you don't need to understand the semantics or syntax of the text, TF-IDF would be sufficient. \n",
    "\n",
    "These are general guidelines and the best choice can depend on many factors, including the size and nature of your dataset, the computational resources available, and the specific requirements of your task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup embedders\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "#This function sends a request to create an embedding for text, and retreives the resposne\n",
    "def create_embedding(text):\n",
    "    response = openai.Embedding.create(\n",
    "    model= \"text-embedding-ada-002\",\n",
    "    input = text\n",
    "    )\n",
    "\n",
    "    return response['data'][0]['embedding']\n",
    "\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply TF-IDF Vectorizer\n",
    "X_tfidf_all = vectorizer.fit_transform(reduced_df['Processed_Description_All'])\n",
    "X_tfidf_some = vectorizer.fit_transform(reduced_df['Processed_Description_Some'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create embeddings and export to csv if embeddings have not been created and exported already\n",
    "\n",
    "run_openai_embedder = False\n",
    "\n",
    "if (run_openai_embedder): \n",
    "    X_openai_all = reduced_df['OpenAI_Embeddings_All'] = reduced_df['Processed_Description_All'] .apply(create_embedding)\n",
    "    X_openai_some = reduced_df['OpenAI_Embeddings_Some'] = reduced_df['Processed_Description_Some'] .apply(create_embedding)\n",
    "\n",
    "export_to_csv = False \n",
    "\n",
    "if (export_to_csv):\n",
    "    reduced_df.to_csv('Processed_CPX_Data.csv',index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assuming open ai embeddings have been created and stored in local folder, import csv into data frame\n",
    "openai_embeddings = pd.read_csv('Processed_CPX_Data.csv')[['OpenAI_Embeddings_All','OpenAI_Embeddings_Some']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Embeddings are stored as string represenations of lists. This block evaluates \n",
    "each row in OpenAI_Embeddings_All and OpenAI_Embeddings_Some as list of floats, then creates a \n",
    "2D matrix ''' \n",
    "\n",
    "X_openai_all = np.stack(openai_embeddings.OpenAI_Embeddings_All.apply(eval))\n",
    "X_openai_some = np.stack(openai_embeddings.OpenAI_Embeddings_Some.apply(eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_openai_all = normalize(X_openai_all, norm='l2')\n",
    "X_openai_some = normalize(X_openai_some,norm = 'l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "update issues        273\n",
       "cable issue          112\n",
       "data access issue     97\n",
       "wifi issues           91\n",
       "no details            84\n",
       "vin scan              49\n",
       "fan issue             48\n",
       "hardware issue        41\n",
       "freezes               36\n",
       "decision accuracy     35\n",
       "battery issue         34\n",
       "software issue        29\n",
       "power issue           26\n",
       "shuts off             26\n",
       "testing issue         22\n",
       "display issue         17\n",
       "temp sensor error     16\n",
       "bmis                  14\n",
       "Name: New_Category, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_df.New_Category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Simple label encoding is appropriate for encoding the category or target label values'\n",
    "This assigns a unique integer value to each category or label name '''\n",
    "y = reduced_df.New_Category.values\n",
    "labels = reduced_df.New_Category.values\n",
    "le = LabelEncoder()\n",
    "# Fit the encoder to your categories and transform\n",
    "y = le.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification (Random Forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- OpenAI Embeddings Classification (All Preprocessing Methods)---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into testing and training data set. Set the testing size to 30% and stratify the data on y\n",
    "X_train_all, X_test_all, y_train_all, y_test_all = train_test_split (X_openai_all,y,stratify = y, random_state=42,test_size=.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfclf = RandomForestClassifier(random_state=42)\n",
    "rfclf.fit(X_train_all,y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Train Set Performance (Random Forest All)-----\n",
      "Embedding Method: OpenAI \n",
      "Total Accuracy: 0.9755102040816327\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    battery issue       0.88      0.96      0.92        24\n",
      "             bmis       1.00      0.90      0.95        10\n",
      "      cable issue       0.99      0.99      0.99        78\n",
      "data access issue       0.99      0.99      0.99        68\n",
      "decision accuracy       0.96      0.92      0.94        25\n",
      "    display issue       0.92      1.00      0.96        12\n",
      "        fan issue       0.97      1.00      0.99        34\n",
      "          freezes       0.96      1.00      0.98        25\n",
      "   hardware issue       1.00      0.90      0.95        29\n",
      "       no details       1.00      1.00      1.00        59\n",
      "      power issue       1.00      0.89      0.94        18\n",
      "        shuts off       0.89      0.94      0.92        18\n",
      "   software issue       1.00      0.95      0.97        20\n",
      "temp sensor error       0.92      1.00      0.96        11\n",
      "    testing issue       1.00      1.00      1.00        15\n",
      "    update issues       0.99      0.99      0.99       191\n",
      "         vin scan       0.97      0.94      0.96        34\n",
      "      wifi issues       0.95      0.97      0.96        64\n",
      "\n",
      "         accuracy                           0.98       735\n",
      "        macro avg       0.97      0.96      0.96       735\n",
      "     weighted avg       0.98      0.98      0.98       735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_train_all = rfclf.predict(X_train_all)  # Predictions for train set\n",
    "y_pred_test_all = rfclf.predict(X_test_all)   #Predictions for the test set\n",
    "\n",
    "#Print predicitons for the train set\n",
    "target_names = le.classes_ \n",
    "print(f'''-----Train Set Performance (Random Forest All)-----\n",
    "Embedding Method: OpenAI \n",
    "Total Accuracy: {accuracy_score(y_train_all, y_pred_train_all)}\\n\n",
    "{classification_report(y_train_all, y_pred_train_all,target_names=target_names)}''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Test Set Performance (Random Forest All)-----\n",
      "Embedding Method: OpenAI\n",
      "Total Accuracy:0.546031746031746\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    battery issue       0.40      0.20      0.27        10\n",
      "             bmis       1.00      0.00      0.00         4\n",
      "      cable issue       0.53      0.68      0.60        34\n",
      "data access issue       0.48      0.76      0.59        29\n",
      "decision accuracy       0.00      0.00      0.00        10\n",
      "    display issue       1.00      0.00      0.00         5\n",
      "        fan issue       1.00      0.14      0.25        14\n",
      "          freezes       1.00      0.09      0.17        11\n",
      "   hardware issue       0.33      0.08      0.13        12\n",
      "       no details       0.95      0.80      0.87        25\n",
      "      power issue       1.00      0.12      0.22         8\n",
      "        shuts off       0.50      0.12      0.20         8\n",
      "   software issue       0.00      0.00      0.00         9\n",
      "temp sensor error       1.00      0.00      0.00         5\n",
      "    testing issue       1.00      0.29      0.44         7\n",
      "    update issues       0.48      0.95      0.63        82\n",
      "         vin scan       0.75      0.40      0.52        15\n",
      "      wifi issues       0.87      0.48      0.62        27\n",
      "\n",
      "         accuracy                           0.55       315\n",
      "        macro avg       0.68      0.28      0.31       315\n",
      "     weighted avg       0.62      0.55      0.48       315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print predictions for the test set\n",
    "print(f'''-----Test Set Performance (Random Forest All)-----\n",
    "Embedding Method: OpenAI\n",
    "Total Accuracy:{accuracy_score(y_test_all, y_pred_test_all)}\\n\n",
    "{classification_report(y_test_all, y_pred_test_all,zero_division = 1,target_names=target_names)}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- OpenAI Embeddings Classification (Some Preprocessing Methods)---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into testing and training data set. Set the testing size to 30% and stratify the data on y\n",
    "X_train_some, X_test_some, y_train_some, y_test_some = train_test_split (X_openai_some,y,stratify = y, random_state=42,test_size=.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfclf2 = RandomForestClassifier(random_state=42)\n",
    "rfclf2.fit(X_train_some,y_train_some)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Test Set Performance (Random Forest Some)----- \n",
      "Embedding Method: OpenAI\n",
      "Total Accuracy: 0.9782312925170068\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    battery issue       0.96      0.92      0.94        24\n",
      "             bmis       1.00      1.00      1.00        10\n",
      "      cable issue       0.97      0.99      0.98        78\n",
      "data access issue       0.99      0.99      0.99        68\n",
      "decision accuracy       1.00      0.96      0.98        25\n",
      "    display issue       0.92      1.00      0.96        12\n",
      "        fan issue       0.97      1.00      0.99        34\n",
      "          freezes       0.96      0.92      0.94        25\n",
      "   hardware issue       0.93      0.97      0.95        29\n",
      "       no details       1.00      1.00      1.00        59\n",
      "      power issue       1.00      0.94      0.97        18\n",
      "        shuts off       1.00      0.94      0.97        18\n",
      "   software issue       1.00      0.95      0.97        20\n",
      "temp sensor error       0.92      1.00      0.96        11\n",
      "    testing issue       1.00      1.00      1.00        15\n",
      "    update issues       0.99      0.99      0.99       191\n",
      "         vin scan       0.97      0.94      0.96        34\n",
      "      wifi issues       0.95      0.97      0.96        64\n",
      "\n",
      "         accuracy                           0.98       735\n",
      "        macro avg       0.97      0.97      0.97       735\n",
      "     weighted avg       0.98      0.98      0.98       735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_train_some = rfclf2.predict(X_train_some)  # Predictions for train set\n",
    "y_pred_test_some = rfclf2.predict(X_test_some)   #Predictions for the test set\n",
    "\n",
    "#Print predicitons for the train set\n",
    "print(f'''-----Test Set Performance (Random Forest Some)----- \n",
    "Embedding Method: OpenAI\n",
    "Total Accuracy: {accuracy_score(y_train_some, y_pred_train_some)}\\n\n",
    "{classification_report(y_train_some, y_pred_train_some,zero_division = 1,target_names=target_names)}''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Test Set Performance (Random Forest Some)-----\n",
      "Embedding Method: OpenAI \n",
      "Total Accuracy:0.6222222222222222\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    battery issue       0.62      0.50      0.56        10\n",
      "             bmis       1.00      0.00      0.00         4\n",
      "      cable issue       0.60      0.88      0.71        34\n",
      "data access issue       0.44      0.79      0.57        29\n",
      "decision accuracy       0.00      0.00      0.00        10\n",
      "    display issue       1.00      0.00      0.00         5\n",
      "        fan issue       0.60      0.21      0.32        14\n",
      "          freezes       0.75      0.27      0.40        11\n",
      "   hardware issue       0.25      0.08      0.12        12\n",
      "       no details       0.96      0.92      0.94        25\n",
      "      power issue       1.00      0.12      0.22         8\n",
      "        shuts off       0.50      0.12      0.20         8\n",
      "   software issue       0.00      0.00      0.00         9\n",
      "temp sensor error       1.00      0.00      0.00         5\n",
      "    testing issue       1.00      0.29      0.44         7\n",
      "    update issues       0.60      0.95      0.74        82\n",
      "         vin scan       0.71      0.33      0.45        15\n",
      "      wifi issues       0.84      0.78      0.81        27\n",
      "\n",
      "         accuracy                           0.62       315\n",
      "        macro avg       0.66      0.35      0.36       315\n",
      "     weighted avg       0.63      0.62      0.56       315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print predictions for the test set\n",
    "print(f'''-----Test Set Performance (Random Forest Some)-----\n",
    "Embedding Method: OpenAI \n",
    "Total Accuracy:{accuracy_score(y_test_some, y_pred_test_some)}\\n\n",
    "{classification_report(y_test_some, y_pred_test_some, zero_division = 1,target_names=target_names)}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- TFIDF Embeddings Classification (All Preprocessing Methods)---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all, X_test_all, y_train_all, y_test_all = train_test_split (X_tfidf_all,y,stratify = y, random_state=42,test_size=.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfclf = RandomForestClassifier(random_state=42)\n",
    "rfclf.fit(X_train_all,y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Train Set Performance (Random Forest All)-----\n",
      "Embedding Method: TFIDF \n",
      "Total Accuracy: 0.9700680272108844\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    battery issue       0.85      0.96      0.90        24\n",
      "             bmis       1.00      0.90      0.95        10\n",
      "      cable issue       0.95      0.99      0.97        78\n",
      "data access issue       0.99      0.99      0.99        68\n",
      "decision accuracy       1.00      0.88      0.94        25\n",
      "    display issue       0.92      1.00      0.96        12\n",
      "        fan issue       0.97      1.00      0.99        34\n",
      "          freezes       0.96      0.92      0.94        25\n",
      "   hardware issue       1.00      0.90      0.95        29\n",
      "       no details       1.00      1.00      1.00        59\n",
      "      power issue       1.00      0.89      0.94        18\n",
      "        shuts off       0.89      0.94      0.92        18\n",
      "   software issue       1.00      0.90      0.95        20\n",
      "temp sensor error       0.92      1.00      0.96        11\n",
      "    testing issue       1.00      1.00      1.00        15\n",
      "    update issues       0.98      1.00      0.99       191\n",
      "         vin scan       0.94      0.97      0.96        34\n",
      "      wifi issues       0.97      0.94      0.95        64\n",
      "\n",
      "         accuracy                           0.97       735\n",
      "        macro avg       0.96      0.95      0.96       735\n",
      "     weighted avg       0.97      0.97      0.97       735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_train_all = rfclf.predict(X_train_all)  # Predictions for train set\n",
    "y_pred_test_all = rfclf.predict(X_test_all)   #Predictions for the test set\n",
    "\n",
    "#Print predicitons for the train set\n",
    "print(f'''-----Train Set Performance (Random Forest All)-----\n",
    "Embedding Method: TFIDF \n",
    "Total Accuracy: {accuracy_score(y_train_all, y_pred_train_all)}\\n\n",
    "{classification_report(y_train_all, y_pred_train_all,target_names=target_names)}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Test Set Performance (Random Forest All)-----\n",
      "Embedding Method: TFIDF\n",
      "Total Accuracy:0.6793650793650794\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    battery issue       0.50      0.50      0.50        10\n",
      "             bmis       1.00      0.00      0.00         4\n",
      "      cable issue       0.58      0.85      0.69        34\n",
      "data access issue       0.60      0.86      0.70        29\n",
      "decision accuracy       0.33      0.10      0.15        10\n",
      "    display issue       1.00      0.00      0.00         5\n",
      "        fan issue       0.78      0.50      0.61        14\n",
      "          freezes       0.80      0.36      0.50        11\n",
      "   hardware issue       0.25      0.08      0.12        12\n",
      "       no details       0.62      0.92      0.74        25\n",
      "      power issue       1.00      0.25      0.40         8\n",
      "        shuts off       0.50      0.12      0.20         8\n",
      "   software issue       0.00      0.00      0.00         9\n",
      "temp sensor error       1.00      0.60      0.75         5\n",
      "    testing issue       1.00      0.29      0.44         7\n",
      "    update issues       0.73      0.94      0.82        82\n",
      "         vin scan       0.64      0.60      0.62        15\n",
      "      wifi issues       0.96      0.93      0.94        27\n",
      "\n",
      "         accuracy                           0.68       315\n",
      "        macro avg       0.68      0.44      0.46       315\n",
      "     weighted avg       0.67      0.68      0.63       315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print predictions for the test set\n",
    "print(f'''-----Test Set Performance (Random Forest All)-----\n",
    "Embedding Method: TFIDF\n",
    "Total Accuracy:{accuracy_score(y_test_all, y_pred_test_all)}\\n\n",
    "{classification_report(y_test_all, y_pred_test_all,zero_division = 1,target_names=target_names)}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- TFIDF Embeddings Classification (Some Preprocessing Methods)---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_some, X_test_some, y_train_some, y_test_some = train_test_split (X_tfidf_some,y,stratify = y, random_state=42,test_size=.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfclf2 = RandomForestClassifier(random_state=42)\n",
    "rfclf2.fit(X_train_some,y_train_some)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Train Set Performance (Random Forest Some)----\n",
      "Embedding Method: TFIDF \n",
      "Total Accuracy: 0.9700680272108844\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    battery issue       0.85      0.96      0.90        24\n",
      "             bmis       1.00      0.90      0.95        10\n",
      "      cable issue       0.96      0.97      0.97        78\n",
      "data access issue       0.99      0.99      0.99        68\n",
      "decision accuracy       1.00      0.88      0.94        25\n",
      "    display issue       0.92      1.00      0.96        12\n",
      "        fan issue       0.97      1.00      0.99        34\n",
      "          freezes       0.96      0.92      0.94        25\n",
      "   hardware issue       1.00      0.90      0.95        29\n",
      "       no details       1.00      1.00      1.00        59\n",
      "      power issue       1.00      0.89      0.94        18\n",
      "        shuts off       0.89      0.94      0.92        18\n",
      "   software issue       0.95      0.95      0.95        20\n",
      "temp sensor error       0.92      1.00      0.96        11\n",
      "    testing issue       1.00      1.00      1.00        15\n",
      "    update issues       0.98      1.00      0.99       191\n",
      "         vin scan       0.94      0.97      0.96        34\n",
      "      wifi issues       0.97      0.94      0.95        64\n",
      "\n",
      "         accuracy                           0.97       735\n",
      "        macro avg       0.96      0.96      0.96       735\n",
      "     weighted avg       0.97      0.97      0.97       735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_train_some = rfclf2.predict(X_train_some)  # Predictions for train set\n",
    "y_pred_test_some = rfclf2.predict(X_test_some)   #Predictions for the test set\n",
    "\n",
    "#Print predicitons for the train set\n",
    "print(f'''-----Train Set Performance (Random Forest Some)----\n",
    "Embedding Method: TFIDF \n",
    "Total Accuracy: {accuracy_score(y_train_some, y_pred_train_some)}\\n\n",
    "{classification_report(y_train_some, y_pred_train_some,zero_division = 1,target_names=target_names)}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Test Set Performance(Random Forest Some)-----\n",
      "Embedding Method: TFIDF\n",
      "Total Accuracy:0.6285714285714286\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    battery issue       0.62      0.50      0.56        10\n",
      "             bmis       1.00      0.00      0.00         4\n",
      "      cable issue       0.55      0.76      0.64        34\n",
      "data access issue       0.47      0.79      0.59        29\n",
      "decision accuracy       0.50      0.10      0.17        10\n",
      "    display issue       1.00      0.00      0.00         5\n",
      "        fan issue       0.67      0.29      0.40        14\n",
      "          freezes       1.00      0.18      0.31        11\n",
      "   hardware issue       0.50      0.17      0.25        12\n",
      "       no details       0.85      0.92      0.88        25\n",
      "      power issue       1.00      0.12      0.22         8\n",
      "        shuts off       0.33      0.12      0.18         8\n",
      "   software issue       0.00      0.00      0.00         9\n",
      "temp sensor error       1.00      0.00      0.00         5\n",
      "    testing issue       1.00      0.29      0.44         7\n",
      "    update issues       0.62      0.96      0.76        82\n",
      "         vin scan       0.58      0.47      0.52        15\n",
      "      wifi issues       0.92      0.81      0.86        27\n",
      "\n",
      "         accuracy                           0.63       315\n",
      "        macro avg       0.70      0.36      0.38       315\n",
      "     weighted avg       0.66      0.63      0.57       315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print predictions for the test set\n",
    "print(f'''-----Test Set Performance(Random Forest Some)-----\n",
    "Embedding Method: TFIDF\n",
    "Total Accuracy:{accuracy_score(y_test_some, y_pred_test_some)}\\n\n",
    "{classification_report(y_test_some, y_pred_test_some, zero_division = 1,target_names=target_names)}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification (XGBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- OpenAI Embeddings Classification (All Preprocessing Methods)---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into testing and training data set. Set the testing size to 30% and stratify the data on y\n",
    "X_train_all, X_test_all, y_train_all, y_test_all = train_test_split (X_openai_all,y,stratify = y, random_state=42,test_size=.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softmax&#x27;, predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softmax&#x27;, predictor=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
       "              objective='multi:softmax', predictor=None, ...)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbclf = XGBClassifier(objective='multi:softmax', random_state=42, n_jobs = -1)\n",
    "xgbclf.fit(X_train_all,y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Train Set Performance (XGBoost All)-----\n",
      "Embedding Method: OpenAI\n",
      "Total Accuracy: 0.9755102040816327\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    battery issue       1.00      0.92      0.96        24\n",
      "             bmis       0.91      1.00      0.95        10\n",
      "      cable issue       0.95      1.00      0.97        78\n",
      "data access issue       0.99      0.99      0.99        68\n",
      "decision accuracy       0.92      0.96      0.94        25\n",
      "    display issue       1.00      0.92      0.96        12\n",
      "        fan issue       0.97      1.00      0.99        34\n",
      "          freezes       0.96      1.00      0.98        25\n",
      "   hardware issue       0.96      0.93      0.95        29\n",
      "       no details       1.00      1.00      1.00        59\n",
      "      power issue       1.00      0.89      0.94        18\n",
      "        shuts off       0.94      0.89      0.91        18\n",
      "   software issue       0.95      1.00      0.98        20\n",
      "temp sensor error       1.00      0.91      0.95        11\n",
      "    testing issue       1.00      1.00      1.00        15\n",
      "    update issues       0.99      0.99      0.99       191\n",
      "         vin scan       1.00      0.91      0.95        34\n",
      "      wifi issues       0.95      0.97      0.96        64\n",
      "\n",
      "         accuracy                           0.98       735\n",
      "        macro avg       0.97      0.96      0.97       735\n",
      "     weighted avg       0.98      0.98      0.98       735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_train_all = xgbclf.predict(X_train_all)  # Predictions for train set\n",
    "y_pred_test_all = xgbclf.predict(X_test_all)   #Predictions for the test set\n",
    "\n",
    "#Print predicitons for the train set\n",
    "print(f'''-----Train Set Performance (XGBoost All)-----\n",
    "Embedding Method: OpenAI\n",
    "Total Accuracy: {accuracy_score(y_train_all, y_pred_train_all)}\\n\n",
    "{classification_report(y_train_all, y_pred_train_all,target_names=target_names)}''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Test Set Performance (XGBoost All)-----\n",
      "Embedding Method: OpenAI\n",
      "Total Accuracy:0.6222222222222222\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    battery issue       0.36      0.50      0.42        10\n",
      "             bmis       0.00      0.00      0.00         4\n",
      "      cable issue       0.58      0.76      0.66        34\n",
      "data access issue       0.52      0.79      0.63        29\n",
      "decision accuracy       0.00      0.00      0.00        10\n",
      "    display issue       0.50      0.20      0.29         5\n",
      "        fan issue       0.33      0.14      0.20        14\n",
      "          freezes       0.60      0.27      0.37        11\n",
      "   hardware issue       0.33      0.17      0.22        12\n",
      "       no details       0.72      0.84      0.78        25\n",
      "      power issue       1.00      0.12      0.22         8\n",
      "        shuts off       0.50      0.12      0.20         8\n",
      "   software issue       0.25      0.11      0.15         9\n",
      "temp sensor error       1.00      0.20      0.33         5\n",
      "    testing issue       0.60      0.43      0.50         7\n",
      "    update issues       0.68      0.94      0.79        82\n",
      "         vin scan       0.78      0.47      0.58        15\n",
      "      wifi issues       0.92      0.81      0.86        27\n",
      "\n",
      "         accuracy                           0.62       315\n",
      "        macro avg       0.54      0.38      0.40       315\n",
      "     weighted avg       0.60      0.62      0.58       315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print predictions for the test set\n",
    "print(f'''-----Test Set Performance (XGBoost All)-----\n",
    "Embedding Method: OpenAI\n",
    "Total Accuracy:{accuracy_score(y_test_all, y_pred_test_all)}\\n\n",
    "{classification_report(y_test_all, y_pred_test_all,zero_division = 1,target_names=target_names)}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- OpenAI Embeddings Classification (Some Preprocessing Methods)---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into testing and training data set. Set the testing size to 30% and stratify the data on y\n",
    "X_train_some, X_test_some, y_train_some, y_test_some = train_test_split (X_openai_some,y,stratify = y, random_state=42,test_size=.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=-1, num_class=20, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softmax&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=-1, num_class=20, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softmax&#x27;, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=-1, num_class=20, num_parallel_tree=None,\n",
       "              objective='multi:softmax', ...)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbclf2 = XGBClassifier(objective='multi:softmax',num_class = 20, random_state=42, n_jobs = -1)\n",
    "xgbclf2.fit(X_train_some,y_train_some)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Train Set Performance (XGBoost Some)----- \n",
      "Embedding Method: OpenAI\n",
      "Total Accuracy: 0.9782312925170068\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    battery issue       0.96      0.92      0.94        24\n",
      "             bmis       1.00      1.00      1.00        10\n",
      "      cable issue       0.96      0.99      0.97        78\n",
      "data access issue       1.00      0.97      0.99        68\n",
      "decision accuracy       1.00      0.96      0.98        25\n",
      "    display issue       1.00      0.92      0.96        12\n",
      "        fan issue       0.97      1.00      0.99        34\n",
      "          freezes       0.96      0.92      0.94        25\n",
      "   hardware issue       0.97      0.97      0.97        29\n",
      "       no details       1.00      1.00      1.00        59\n",
      "      power issue       0.95      1.00      0.97        18\n",
      "        shuts off       0.95      1.00      0.97        18\n",
      "   software issue       0.95      1.00      0.98        20\n",
      "temp sensor error       1.00      0.91      0.95        11\n",
      "    testing issue       1.00      1.00      1.00        15\n",
      "    update issues       0.99      0.99      0.99       191\n",
      "         vin scan       1.00      0.91      0.95        34\n",
      "      wifi issues       0.94      0.98      0.96        64\n",
      "\n",
      "         accuracy                           0.98       735\n",
      "        macro avg       0.98      0.97      0.97       735\n",
      "     weighted avg       0.98      0.98      0.98       735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_train_some = xgbclf2.predict(X_train_some)  # Predictions for train set\n",
    "y_pred_test_some = xgbclf2.predict(X_test_some)   #Predictions for the test set\n",
    "\n",
    "#Print predicitons for the train set\n",
    "print(f'''-----Train Set Performance (XGBoost Some)----- \n",
    "Embedding Method: OpenAI\n",
    "Total Accuracy: {accuracy_score(y_train_some, y_pred_train_some)}\\n\n",
    "{classification_report(y_train_some, y_pred_train_some,zero_division = 1,target_names=target_names)}''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Test Set Performance (XGBoost Some)----- \n",
      "Embedding Method: OpenAI\n",
      "Total Accuracy:0.6412698412698413\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    battery issue       0.50      0.50      0.50        10\n",
      "             bmis       1.00      0.00      0.00         4\n",
      "      cable issue       0.57      0.76      0.65        34\n",
      "data access issue       0.46      0.66      0.54        29\n",
      "decision accuracy       0.17      0.10      0.12        10\n",
      "    display issue       0.00      0.00      0.00         5\n",
      "        fan issue       0.57      0.29      0.38        14\n",
      "          freezes       0.40      0.36      0.38        11\n",
      "   hardware issue       0.25      0.25      0.25        12\n",
      "       no details       0.74      0.92      0.82        25\n",
      "      power issue       0.33      0.12      0.18         8\n",
      "        shuts off       0.33      0.12      0.18         8\n",
      "   software issue       0.20      0.11      0.14         9\n",
      "temp sensor error       1.00      0.40      0.57         5\n",
      "    testing issue       1.00      0.29      0.44         7\n",
      "    update issues       0.80      0.93      0.86        82\n",
      "         vin scan       0.86      0.80      0.83        15\n",
      "      wifi issues       0.92      0.81      0.86        27\n",
      "\n",
      "         accuracy                           0.64       315\n",
      "        macro avg       0.56      0.41      0.43       315\n",
      "     weighted avg       0.63      0.64      0.61       315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print predictions for the test set\n",
    "print(f'''-----Test Set Performance (XGBoost Some)----- \n",
    "Embedding Method: OpenAI\n",
    "Total Accuracy:{accuracy_score(y_test_some, y_pred_test_some)}\\n\n",
    "{classification_report(y_test_some, y_pred_test_some, zero_division = 1,target_names=target_names)}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- TFIDF Embeddings Classification (All Preprocessing Methods)---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all, X_test_all, y_train_all, y_test_all = train_test_split (X_tfidf_all,y,stratify = y, random_state=42,test_size=.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softmax&#x27;, predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softmax&#x27;, predictor=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
       "              objective='multi:softmax', predictor=None, ...)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbclf = XGBClassifier(objective='multi:softmax', random_state=42, n_jobs = -1)\n",
    "xgbclf.fit(X_train_all,y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Train Set Performance (XGBoost All)----- \n",
      "Embedding Method: TFIDF\n",
      "Total Accuracy: 0.9687074829931973\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    battery issue       1.00      0.88      0.93        24\n",
      "             bmis       0.91      1.00      0.95        10\n",
      "      cable issue       0.96      0.97      0.97        78\n",
      "data access issue       0.99      0.99      0.99        68\n",
      "decision accuracy       0.96      0.92      0.94        25\n",
      "    display issue       0.92      1.00      0.96        12\n",
      "        fan issue       0.97      1.00      0.99        34\n",
      "          freezes       0.89      1.00      0.94        25\n",
      "   hardware issue       0.90      0.93      0.92        29\n",
      "       no details       0.98      1.00      0.99        59\n",
      "      power issue       1.00      0.89      0.94        18\n",
      "        shuts off       0.94      0.89      0.91        18\n",
      "   software issue       0.95      0.95      0.95        20\n",
      "temp sensor error       0.92      1.00      0.96        11\n",
      "    testing issue       1.00      1.00      1.00        15\n",
      "    update issues       0.99      0.99      0.99       191\n",
      "         vin scan       0.94      0.97      0.96        34\n",
      "      wifi issues       0.98      0.92      0.95        64\n",
      "\n",
      "         accuracy                           0.97       735\n",
      "        macro avg       0.96      0.96      0.96       735\n",
      "     weighted avg       0.97      0.97      0.97       735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_train_all = xgbclf.predict(X_train_all)  # Predictions for train set\n",
    "y_pred_test_all = xgbclf.predict(X_test_all)   #Predictions for the test set\n",
    "\n",
    "#Print predicitons for the train set\n",
    "print(f'''-----Train Set Performance (XGBoost All)----- \n",
    "Embedding Method: TFIDF\n",
    "Total Accuracy: {accuracy_score(y_train_all, y_pred_train_all)}\\n\n",
    "{classification_report(y_train_all, y_pred_train_all,target_names=target_names)}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Test Set Performance (XGBoost All)----- \n",
      "Embedding Method: TFIDF\n",
      "Total Accuracy:0.6952380952380952\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    battery issue       0.45      0.50      0.48        10\n",
      "             bmis       0.50      0.25      0.33         4\n",
      "      cable issue       0.74      0.85      0.79        34\n",
      "data access issue       0.58      0.76      0.66        29\n",
      "decision accuracy       0.27      0.30      0.29        10\n",
      "    display issue       0.50      0.20      0.29         5\n",
      "        fan issue       0.73      0.57      0.64        14\n",
      "          freezes       0.67      0.36      0.47        11\n",
      "   hardware issue       0.27      0.25      0.26        12\n",
      "       no details       0.79      0.92      0.85        25\n",
      "      power issue       0.40      0.25      0.31         8\n",
      "        shuts off       0.22      0.25      0.24         8\n",
      "   software issue       0.17      0.11      0.13         9\n",
      "temp sensor error       1.00      0.60      0.75         5\n",
      "    testing issue       1.00      0.43      0.60         7\n",
      "    update issues       0.86      0.91      0.89        82\n",
      "         vin scan       0.60      0.60      0.60        15\n",
      "      wifi issues       0.93      0.93      0.93        27\n",
      "\n",
      "         accuracy                           0.70       315\n",
      "        macro avg       0.59      0.50      0.53       315\n",
      "     weighted avg       0.69      0.70      0.68       315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print predictions for the test set\n",
    "print(f'''-----Test Set Performance (XGBoost All)----- \n",
    "Embedding Method: TFIDF\n",
    "Total Accuracy:{accuracy_score(y_test_all, y_pred_test_all)}\\n\n",
    "{classification_report(y_test_all, y_pred_test_all,zero_division = 1,target_names=target_names)}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- TFIDF Embeddings Classification (Some Preprocessing Methods)---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_some, X_test_some, y_train_some, y_test_some = train_test_split (X_tfidf_some,y,stratify = y, random_state=42,test_size=.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softmax&#x27;, predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softmax&#x27;, predictor=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
       "              objective='multi:softmax', predictor=None, ...)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbclf2 = XGBClassifier(objective='multi:softmax', random_state=42, n_jobs = -1)\n",
    "xgbclf2.fit(X_train_some,y_train_some)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Train Set Performance (XGBoost Some)----- \n",
      "Embedding Method: TFIDF \n",
      "Total Accuracy: 0.9700680272108844\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    battery issue       0.96      0.92      0.94        24\n",
      "             bmis       1.00      0.90      0.95        10\n",
      "      cable issue       0.95      0.99      0.97        78\n",
      "data access issue       1.00      0.97      0.99        68\n",
      "decision accuracy       0.96      0.92      0.94        25\n",
      "    display issue       1.00      0.92      0.96        12\n",
      "        fan issue       0.97      1.00      0.99        34\n",
      "          freezes       0.96      0.92      0.94        25\n",
      "   hardware issue       0.90      0.93      0.92        29\n",
      "       no details       1.00      1.00      1.00        59\n",
      "      power issue       1.00      0.89      0.94        18\n",
      "        shuts off       0.89      0.94      0.92        18\n",
      "   software issue       0.95      0.95      0.95        20\n",
      "temp sensor error       0.92      1.00      0.96        11\n",
      "    testing issue       1.00      1.00      1.00        15\n",
      "    update issues       0.98      1.00      0.99       191\n",
      "         vin scan       0.94      0.97      0.96        34\n",
      "      wifi issues       0.97      0.94      0.95        64\n",
      "\n",
      "         accuracy                           0.97       735\n",
      "        macro avg       0.96      0.95      0.96       735\n",
      "     weighted avg       0.97      0.97      0.97       735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_train_some = xgbclf2.predict(X_train_some)  # Predictions for train set\n",
    "y_pred_test_some = xgbclf2.predict(X_test_some)   #Predictions for the test set\n",
    "\n",
    "#Print predicitons for the train set\n",
    "print(f'''-----Train Set Performance (XGBoost Some)----- \n",
    "Embedding Method: TFIDF \n",
    "Total Accuracy: {accuracy_score(y_train_some, y_pred_train_some)}\\n\n",
    "{classification_report(y_train_some, y_pred_train_some,zero_division = 1,target_names=target_names)}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Test Set Performance (XGBoost Some)----- \n",
      "Embedding Method: TFIDF\n",
      "Total Accuracy:0.6412698412698413\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    battery issue       0.45      0.50      0.48        10\n",
      "             bmis       0.00      0.00      0.00         4\n",
      "      cable issue       0.62      0.74      0.68        34\n",
      "data access issue       0.46      0.66      0.54        29\n",
      "decision accuracy       0.11      0.10      0.11        10\n",
      "    display issue       0.00      0.00      0.00         5\n",
      "        fan issue       0.50      0.29      0.36        14\n",
      "          freezes       0.83      0.45      0.59        11\n",
      "   hardware issue       0.27      0.25      0.26        12\n",
      "       no details       0.92      0.96      0.94        25\n",
      "      power issue       0.67      0.25      0.36         8\n",
      "        shuts off       0.14      0.12      0.13         8\n",
      "   software issue       0.00      0.00      0.00         9\n",
      "temp sensor error       0.75      0.60      0.67         5\n",
      "    testing issue       0.60      0.43      0.50         7\n",
      "    update issues       0.81      0.91      0.86        82\n",
      "         vin scan       0.57      0.53      0.55        15\n",
      "      wifi issues       0.86      0.89      0.87        27\n",
      "\n",
      "         accuracy                           0.64       315\n",
      "        macro avg       0.48      0.43      0.44       315\n",
      "     weighted avg       0.62      0.64      0.62       315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print predictions for the test set\n",
    "print(f'''-----Test Set Performance (XGBoost Some)----- \n",
    "Embedding Method: TFIDF\n",
    "Total Accuracy:{accuracy_score(y_test_some, y_pred_test_some)}\\n\n",
    "{classification_report(y_test_some, y_pred_test_some, zero_division = 1,target_names=target_names)}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Results\n",
    "\n",
    "After comparing the different classification reports of Random Forest and XGBoost with all and some of the preprocessing steps applied, the best combination of model and preprocessing steps was XGBoost with TFIDF using all preprocessing steps. XGBoost with TFIDF and all processing steps acheived a test set accuracy score of .70 and an f1-score of .69 without hyperparameter tuning. The next step is to tune the xgboost hyperparameters to potentially increase accruacy and f1 score. If hyperparameter tuning is not enough, other methods such as ensemble learning will be implementd. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimized Hyperparameter Tuning with Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning with Optuna involves automatically searching for the best combination of hyperparameters for a machine learning model. Optuna uses an optimization algorithm, such as the Tree-structured Parzen Estimator (TPE), to efficiently explore the hyperparameter search space and find the optimal values.\n",
    "\n",
    "In the code, the `objective` function defines the model and the hyperparameters to be optimized. Optuna suggests different hyperparameter values during the optimization process, and the `objective` function evaluates the model's performance using these suggested values. The evaluation metric, such as F1 score, is used to assess the model's quality. Optuna tracks the evaluation metric and adjusts the suggested hyperparameters accordingly.\n",
    "\n",
    "The `study.optimize` method initiates the hyperparameter optimization process. It runs a specified number of trials, evaluating different combinations of hyperparameters. Optuna keeps track of the best-performing set of hyperparameters based on the evaluation metric. After all trials are completed, the best trial is retrieved using `study.best_trial`, and the optimal hyperparameters and their corresponding evaluation metric value are printed.\n",
    "\n",
    "Overall, Optuna automates the process of hyperparameter tuning, efficiently exploring the hyperparameter space and identifying the best configuration for the given machine learning task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all, X_temp_all, y_train_all, y_temp_all = train_test_split (X_tfidf_all,y,stratify = y, random_state=42,test_size=.30)\n",
    "X_val_all, X_test_all, y_val_all, y_test_all = train_test_split (X_temp_all,y_temp_all,stratify = y_temp_all, random_state=42,test_size=.50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-02 18:43:27,411] A new study created in memory with name: no-name-18bfa29a-6733-40ea-8715-c027b033c464\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d822928975624c1c8b5e72446f547e65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-08-02 18:43:39,813] Trial 1 finished with value: 0.6655290088027407 and parameters: {'n_estimators': 130, 'max_depth': 2, 'learning_rate': 0.8774948823587133, 'subsample': 0.8236790507540539, 'colsample_bytree': 0.473768865829419, 'gamma': 0.7125207457824918, 'reg_lambda': 0.4122492656428716, 'reg_alpha': 0.14853349841907745}. Best is trial 1 with value: 0.6655290088027407.\n",
      "[I 2023-08-02 18:43:39,875] Trial 0 pruned. Trial was pruned at iteration 126.\n",
      "[I 2023-08-02 18:43:39,883] Trial 7 pruned. Trial was pruned at iteration 127.\n",
      "[I 2023-08-02 18:43:39,890] Trial 5 pruned. Trial was pruned at iteration 131.\n",
      "[I 2023-08-02 18:43:41,425] Trial 3 finished with value: 0.6436525077915176 and parameters: {'n_estimators': 172, 'max_depth': 1, 'learning_rate': 0.45931714831810627, 'subsample': 0.751023142226025, 'colsample_bytree': 0.5952824313732179, 'gamma': 0.6096271656764756, 'reg_lambda': 1.0241438508683265, 'reg_alpha': 1.7308089740114365}. Best is trial 1 with value: 0.6655290088027407.\n",
      "[I 2023-08-02 18:43:44,283] Trial 4 finished with value: 0.6406981219863414 and parameters: {'n_estimators': 285, 'max_depth': 1, 'learning_rate': 0.828485720302268, 'subsample': 0.5636350879138332, 'colsample_bytree': 0.7333792948098319, 'gamma': 0.7557414968037046, 'reg_lambda': 0.9569193232712906, 'reg_alpha': 1.4249771435252427}. Best is trial 1 with value: 0.6655290088027407.\n",
      "[I 2023-08-02 18:43:44,596] Trial 2 finished with value: 0.6278384441907725 and parameters: {'n_estimators': 290, 'max_depth': 2, 'learning_rate': 0.7136727092573664, 'subsample': 0.6632503682634827, 'colsample_bytree': 0.37055507699516493, 'gamma': 0.6920287791836834, 'reg_lambda': 0.42646901401680354, 'reg_alpha': 0.5684304734360629}. Best is trial 1 with value: 0.6655290088027407.\n",
      "[I 2023-08-02 18:43:45,592] Trial 6 finished with value: 0.6385760475602915 and parameters: {'n_estimators': 369, 'max_depth': 3, 'learning_rate': 0.4398210900327634, 'subsample': 0.6946828070895945, 'colsample_bytree': 0.4375168854789206, 'gamma': 0.5615195045381529, 'reg_lambda': 1.8571925359231845, 'reg_alpha': 1.9282968459324898}. Best is trial 1 with value: 0.6655290088027407.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ZipFile.__del__ at 0x106326660>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/josevera/miniconda3/envs/mlenv/lib/python3.11/zipfile.py\", line 1872, in __del__\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39m# Create a study with a pruner\u001b[39;00m\n\u001b[1;32m     33\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m, pruner\u001b[39m=\u001b[39mHyperbandPruner())\n\u001b[0;32m---> 34\u001b[0m study\u001b[39m.\u001b[39moptimize(objective, n_trials\u001b[39m=\u001b[39m\u001b[39m200\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, show_progress_bar\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     36\u001b[0m \u001b[39m#Print trial, value, and parameters with the best result.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBest trial:\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/mlenv/lib/python3.11/site-packages/optuna/study/study.py:443\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    340\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    349\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[1;32m    352\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m     _optimize(\n\u001b[1;32m    444\u001b[0m         study\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[1;32m    445\u001b[0m         func\u001b[39m=\u001b[39mfunc,\n\u001b[1;32m    446\u001b[0m         n_trials\u001b[39m=\u001b[39mn_trials,\n\u001b[1;32m    447\u001b[0m         timeout\u001b[39m=\u001b[39mtimeout,\n\u001b[1;32m    448\u001b[0m         n_jobs\u001b[39m=\u001b[39mn_jobs,\n\u001b[1;32m    449\u001b[0m         catch\u001b[39m=\u001b[39m\u001b[39mtuple\u001b[39m(catch) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(catch, Iterable) \u001b[39melse\u001b[39;00m (catch,),\n\u001b[1;32m    450\u001b[0m         callbacks\u001b[39m=\u001b[39mcallbacks,\n\u001b[1;32m    451\u001b[0m         gc_after_trial\u001b[39m=\u001b[39mgc_after_trial,\n\u001b[1;32m    452\u001b[0m         show_progress_bar\u001b[39m=\u001b[39mshow_progress_bar,\n\u001b[1;32m    453\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/mlenv/lib/python3.11/site-packages/optuna/study/_optimize.py:100\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(futures) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m n_jobs:\n\u001b[0;32m--> 100\u001b[0m     completed, futures \u001b[39m=\u001b[39m wait(futures, return_when\u001b[39m=\u001b[39mFIRST_COMPLETED)\n\u001b[1;32m    101\u001b[0m     \u001b[39m# Raise if exception occurred in executing the completed futures.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m completed:\n",
      "File \u001b[0;32m~/miniconda3/envs/mlenv/lib/python3.11/concurrent/futures/_base.py:305\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(fs, timeout, return_when)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[39mreturn\u001b[39;00m DoneAndNotDoneFutures(done, not_done)\n\u001b[1;32m    303\u001b[0m     waiter \u001b[39m=\u001b[39m _create_and_install_waiters(fs, return_when)\n\u001b[0;32m--> 305\u001b[0m waiter\u001b[39m.\u001b[39mevent\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    306\u001b[0m \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m fs:\n\u001b[1;32m    307\u001b[0m     \u001b[39mwith\u001b[39;00m f\u001b[39m.\u001b[39m_condition:\n",
      "File \u001b[0;32m~/miniconda3/envs/mlenv/lib/python3.11/threading.py:622\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    620\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    621\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 622\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cond\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    623\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniconda3/envs/mlenv/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Hyperparameter optimization objective function using Optuna.\n",
    "    \n",
    "    Args:\n",
    "        trial: Optuna trial object.\n",
    "    \n",
    "    Returns:\n",
    "        float: Weighted F1 score obtained using the XGBoost model with optimized hyperparameters.\n",
    "    \"\"\"\n",
    "    # Define hyperparameters\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 400),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 3),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.4, 1.0),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3, 0.8),\n",
    "        'gamma': trial.suggest_float('gamma', 0.5, 1.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-4, 2.0),  # L2 regularization\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-4, 2.0),  # L1 regularization\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**params, eval_metric='mlogloss', objective='multi:softprob', random_state=42,\n",
    "                        callbacks=[optuna.integration.XGBoostPruningCallback(trial, observation_key=\"validation_0-mlogloss\")],\n",
    "                        tree_method='hist')\n",
    "    model.fit(X_train_all, y_train_all,eval_set= [(X_val_all,y_val_all)],verbose = 0)\n",
    "    y_pred = model.predict(X_val_all)\n",
    "    f1 = f1_score(y_val_all, y_pred, average='weighted')\n",
    "    \n",
    "    return f1\n",
    "\n",
    "# Create a study with a pruner\n",
    "study = optuna.create_study(direction='maximize', pruner=HyperbandPruner())\n",
    "study.optimize(objective, n_trials=200, n_jobs=-1, show_progress_bar=True)\n",
    "\n",
    "#Print trial, value, and parameters with the best result.\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "\n",
    "print('  Value: ', trial.value)\n",
    "print('  Params: ')\n",
    "for key, value in trial.params.items():\n",
    "    print('    {}: {}'.format(key, value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best XGB Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb_params = {\n",
    "    'n_estimators': 499,\n",
    "    'max_depth': 1,\n",
    "    'learning_rate': 0.6308805211760938,\n",
    "    'subsample': 0.6248763597930178,\n",
    "    'colsample_bytree': 0.34055509207982654,\n",
    "    'gamma': 0.8793020954978124,\n",
    "    'reg_lambda': 1.7276802719908124,\n",
    "    'reg_alpha': 0.2200904663014992}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_xgb = XGBClassifier(**best_xgb_params, eval_metric='merror', objective='multi:softprob', random_state=42, tree_method='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-merror:0.57325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalidation_0-merror:0.55414\n",
      "[2]\tvalidation_0-merror:0.52229\n",
      "[3]\tvalidation_0-merror:0.45860\n",
      "[4]\tvalidation_0-merror:0.43949\n",
      "[5]\tvalidation_0-merror:0.40764\n",
      "[6]\tvalidation_0-merror:0.38217\n",
      "[7]\tvalidation_0-merror:0.36943\n",
      "[8]\tvalidation_0-merror:0.35669\n",
      "[9]\tvalidation_0-merror:0.36306\n",
      "[10]\tvalidation_0-merror:0.33758\n",
      "[11]\tvalidation_0-merror:0.31847\n",
      "[12]\tvalidation_0-merror:0.33121\n",
      "[13]\tvalidation_0-merror:0.35032\n",
      "[14]\tvalidation_0-merror:0.35669\n",
      "[15]\tvalidation_0-merror:0.34395\n",
      "[16]\tvalidation_0-merror:0.32484\n",
      "[17]\tvalidation_0-merror:0.33758\n",
      "[18]\tvalidation_0-merror:0.32484\n",
      "[19]\tvalidation_0-merror:0.30573\n",
      "[20]\tvalidation_0-merror:0.31210\n",
      "[21]\tvalidation_0-merror:0.32484\n",
      "[22]\tvalidation_0-merror:0.29936\n",
      "[23]\tvalidation_0-merror:0.31210\n",
      "[24]\tvalidation_0-merror:0.33121\n",
      "[25]\tvalidation_0-merror:0.34395\n",
      "[26]\tvalidation_0-merror:0.33121\n",
      "[27]\tvalidation_0-merror:0.33121\n",
      "[28]\tvalidation_0-merror:0.32484\n",
      "[29]\tvalidation_0-merror:0.33758\n",
      "[30]\tvalidation_0-merror:0.33121\n",
      "[31]\tvalidation_0-merror:0.33758\n",
      "[32]\tvalidation_0-merror:0.32484\n",
      "[33]\tvalidation_0-merror:0.32484\n",
      "[34]\tvalidation_0-merror:0.33758\n",
      "[35]\tvalidation_0-merror:0.33758\n",
      "[36]\tvalidation_0-merror:0.31847\n",
      "[37]\tvalidation_0-merror:0.31847\n",
      "[38]\tvalidation_0-merror:0.31847\n",
      "[39]\tvalidation_0-merror:0.31847\n",
      "[40]\tvalidation_0-merror:0.32484\n",
      "[41]\tvalidation_0-merror:0.31847\n",
      "[42]\tvalidation_0-merror:0.30573\n",
      "[43]\tvalidation_0-merror:0.31210\n",
      "[44]\tvalidation_0-merror:0.31210\n",
      "[45]\tvalidation_0-merror:0.30573\n",
      "[46]\tvalidation_0-merror:0.30573\n",
      "[47]\tvalidation_0-merror:0.29936\n",
      "[48]\tvalidation_0-merror:0.30573\n",
      "[49]\tvalidation_0-merror:0.31847\n",
      "[50]\tvalidation_0-merror:0.31847\n",
      "[51]\tvalidation_0-merror:0.31847\n",
      "[52]\tvalidation_0-merror:0.31847\n",
      "[53]\tvalidation_0-merror:0.31210\n",
      "[54]\tvalidation_0-merror:0.31210\n",
      "[55]\tvalidation_0-merror:0.30573\n",
      "[56]\tvalidation_0-merror:0.30573\n",
      "[57]\tvalidation_0-merror:0.30573\n",
      "[58]\tvalidation_0-merror:0.31847\n",
      "[59]\tvalidation_0-merror:0.31210\n",
      "[60]\tvalidation_0-merror:0.31210\n",
      "[61]\tvalidation_0-merror:0.30573\n",
      "[62]\tvalidation_0-merror:0.31210\n",
      "[63]\tvalidation_0-merror:0.31210\n",
      "[64]\tvalidation_0-merror:0.31210\n",
      "[65]\tvalidation_0-merror:0.31210\n",
      "[66]\tvalidation_0-merror:0.31210\n",
      "[67]\tvalidation_0-merror:0.31210\n",
      "[68]\tvalidation_0-merror:0.30573\n",
      "[69]\tvalidation_0-merror:0.29936\n",
      "[70]\tvalidation_0-merror:0.31210\n",
      "[71]\tvalidation_0-merror:0.30573\n",
      "[72]\tvalidation_0-merror:0.29936\n",
      "[73]\tvalidation_0-merror:0.31210\n",
      "[74]\tvalidation_0-merror:0.29936\n",
      "[75]\tvalidation_0-merror:0.31210\n",
      "[76]\tvalidation_0-merror:0.30573\n",
      "[77]\tvalidation_0-merror:0.30573\n",
      "[78]\tvalidation_0-merror:0.31210\n",
      "[79]\tvalidation_0-merror:0.31210\n",
      "[80]\tvalidation_0-merror:0.33121\n",
      "[81]\tvalidation_0-merror:0.31847\n",
      "[82]\tvalidation_0-merror:0.30573\n",
      "[83]\tvalidation_0-merror:0.31210\n",
      "[84]\tvalidation_0-merror:0.31210\n",
      "[85]\tvalidation_0-merror:0.31210\n",
      "[86]\tvalidation_0-merror:0.31210\n",
      "[87]\tvalidation_0-merror:0.30573\n",
      "[88]\tvalidation_0-merror:0.31847\n",
      "[89]\tvalidation_0-merror:0.30573\n",
      "[90]\tvalidation_0-merror:0.31210\n",
      "[91]\tvalidation_0-merror:0.31847\n",
      "[92]\tvalidation_0-merror:0.30573\n",
      "[93]\tvalidation_0-merror:0.30573\n",
      "[94]\tvalidation_0-merror:0.30573\n",
      "[95]\tvalidation_0-merror:0.29936\n",
      "[96]\tvalidation_0-merror:0.29299\n",
      "[97]\tvalidation_0-merror:0.29936\n",
      "[98]\tvalidation_0-merror:0.30573\n",
      "[99]\tvalidation_0-merror:0.30573\n",
      "[100]\tvalidation_0-merror:0.29299\n",
      "[101]\tvalidation_0-merror:0.29936\n",
      "[102]\tvalidation_0-merror:0.29936\n",
      "[103]\tvalidation_0-merror:0.29299\n",
      "[104]\tvalidation_0-merror:0.28662\n",
      "[105]\tvalidation_0-merror:0.29299\n",
      "[106]\tvalidation_0-merror:0.29936\n",
      "[107]\tvalidation_0-merror:0.30573\n",
      "[108]\tvalidation_0-merror:0.29299\n",
      "[109]\tvalidation_0-merror:0.28662\n",
      "[110]\tvalidation_0-merror:0.28662\n",
      "[111]\tvalidation_0-merror:0.29299\n",
      "[112]\tvalidation_0-merror:0.29299\n",
      "[113]\tvalidation_0-merror:0.31210\n",
      "[114]\tvalidation_0-merror:0.30573\n",
      "[115]\tvalidation_0-merror:0.30573\n",
      "[116]\tvalidation_0-merror:0.31210\n",
      "[117]\tvalidation_0-merror:0.30573\n",
      "[118]\tvalidation_0-merror:0.30573\n",
      "[119]\tvalidation_0-merror:0.30573\n",
      "[120]\tvalidation_0-merror:0.30573\n",
      "[121]\tvalidation_0-merror:0.29936\n",
      "[122]\tvalidation_0-merror:0.29936\n",
      "[123]\tvalidation_0-merror:0.29936\n",
      "[124]\tvalidation_0-merror:0.30573\n",
      "[125]\tvalidation_0-merror:0.30573\n",
      "[126]\tvalidation_0-merror:0.30573\n",
      "[127]\tvalidation_0-merror:0.30573\n",
      "[128]\tvalidation_0-merror:0.31210\n",
      "[129]\tvalidation_0-merror:0.31210\n",
      "[130]\tvalidation_0-merror:0.31847\n",
      "[131]\tvalidation_0-merror:0.31847\n",
      "[132]\tvalidation_0-merror:0.31847\n",
      "[133]\tvalidation_0-merror:0.31847\n",
      "[134]\tvalidation_0-merror:0.31210\n",
      "[135]\tvalidation_0-merror:0.31847\n",
      "[136]\tvalidation_0-merror:0.30573\n",
      "[137]\tvalidation_0-merror:0.31210\n",
      "[138]\tvalidation_0-merror:0.31210\n",
      "[139]\tvalidation_0-merror:0.30573\n",
      "[140]\tvalidation_0-merror:0.32484\n",
      "[141]\tvalidation_0-merror:0.31847\n",
      "[142]\tvalidation_0-merror:0.32484\n",
      "[143]\tvalidation_0-merror:0.33121\n",
      "[144]\tvalidation_0-merror:0.31847\n",
      "[145]\tvalidation_0-merror:0.31847\n",
      "[146]\tvalidation_0-merror:0.31210\n",
      "[147]\tvalidation_0-merror:0.31210\n",
      "[148]\tvalidation_0-merror:0.31210\n",
      "[149]\tvalidation_0-merror:0.31210\n",
      "[150]\tvalidation_0-merror:0.31210\n",
      "[151]\tvalidation_0-merror:0.31847\n",
      "[152]\tvalidation_0-merror:0.31847\n",
      "[153]\tvalidation_0-merror:0.31847\n",
      "[154]\tvalidation_0-merror:0.31210\n",
      "[155]\tvalidation_0-merror:0.31210\n",
      "[156]\tvalidation_0-merror:0.31210\n",
      "[157]\tvalidation_0-merror:0.31210\n",
      "[158]\tvalidation_0-merror:0.31210\n",
      "[159]\tvalidation_0-merror:0.31210\n",
      "[160]\tvalidation_0-merror:0.31210\n",
      "[161]\tvalidation_0-merror:0.30573\n",
      "[162]\tvalidation_0-merror:0.31210\n",
      "[163]\tvalidation_0-merror:0.30573\n",
      "[164]\tvalidation_0-merror:0.29936\n",
      "[165]\tvalidation_0-merror:0.30573\n",
      "[166]\tvalidation_0-merror:0.30573\n",
      "[167]\tvalidation_0-merror:0.30573\n",
      "[168]\tvalidation_0-merror:0.30573\n",
      "[169]\tvalidation_0-merror:0.30573\n",
      "[170]\tvalidation_0-merror:0.29936\n",
      "[171]\tvalidation_0-merror:0.30573\n",
      "[172]\tvalidation_0-merror:0.30573\n",
      "[173]\tvalidation_0-merror:0.30573\n",
      "[174]\tvalidation_0-merror:0.31210\n",
      "[175]\tvalidation_0-merror:0.31210\n",
      "[176]\tvalidation_0-merror:0.31210\n",
      "[177]\tvalidation_0-merror:0.31210\n",
      "[178]\tvalidation_0-merror:0.30573\n",
      "[179]\tvalidation_0-merror:0.30573\n",
      "[180]\tvalidation_0-merror:0.30573\n",
      "[181]\tvalidation_0-merror:0.30573\n",
      "[182]\tvalidation_0-merror:0.30573\n",
      "[183]\tvalidation_0-merror:0.30573\n",
      "[184]\tvalidation_0-merror:0.29936\n",
      "[185]\tvalidation_0-merror:0.30573\n",
      "[186]\tvalidation_0-merror:0.30573\n",
      "[187]\tvalidation_0-merror:0.31210\n",
      "[188]\tvalidation_0-merror:0.30573\n",
      "[189]\tvalidation_0-merror:0.29299\n",
      "[190]\tvalidation_0-merror:0.29299\n",
      "[191]\tvalidation_0-merror:0.29936\n",
      "[192]\tvalidation_0-merror:0.29299\n",
      "[193]\tvalidation_0-merror:0.29936\n",
      "[194]\tvalidation_0-merror:0.29936\n",
      "[195]\tvalidation_0-merror:0.29936\n",
      "[196]\tvalidation_0-merror:0.29936\n",
      "[197]\tvalidation_0-merror:0.29936\n",
      "[198]\tvalidation_0-merror:0.30573\n",
      "[199]\tvalidation_0-merror:0.31210\n",
      "[200]\tvalidation_0-merror:0.29936\n",
      "[201]\tvalidation_0-merror:0.29299\n",
      "[202]\tvalidation_0-merror:0.30573\n",
      "[203]\tvalidation_0-merror:0.29936\n",
      "[204]\tvalidation_0-merror:0.29936\n",
      "[205]\tvalidation_0-merror:0.30573\n",
      "[206]\tvalidation_0-merror:0.31210\n",
      "[207]\tvalidation_0-merror:0.30573\n",
      "[208]\tvalidation_0-merror:0.30573\n",
      "[209]\tvalidation_0-merror:0.29936\n",
      "[210]\tvalidation_0-merror:0.30573\n",
      "[211]\tvalidation_0-merror:0.30573\n",
      "[212]\tvalidation_0-merror:0.30573\n",
      "[213]\tvalidation_0-merror:0.30573\n",
      "[214]\tvalidation_0-merror:0.30573\n",
      "[215]\tvalidation_0-merror:0.30573\n",
      "[216]\tvalidation_0-merror:0.31210\n",
      "[217]\tvalidation_0-merror:0.31210\n",
      "[218]\tvalidation_0-merror:0.31210\n",
      "[219]\tvalidation_0-merror:0.31847\n",
      "[220]\tvalidation_0-merror:0.29936\n",
      "[221]\tvalidation_0-merror:0.30573\n",
      "[222]\tvalidation_0-merror:0.29936\n",
      "[223]\tvalidation_0-merror:0.31210\n",
      "[224]\tvalidation_0-merror:0.31210\n",
      "[225]\tvalidation_0-merror:0.31210\n",
      "[226]\tvalidation_0-merror:0.30573\n",
      "[227]\tvalidation_0-merror:0.31210\n",
      "[228]\tvalidation_0-merror:0.31210\n",
      "[229]\tvalidation_0-merror:0.30573\n",
      "[230]\tvalidation_0-merror:0.29936\n",
      "[231]\tvalidation_0-merror:0.29936\n",
      "[232]\tvalidation_0-merror:0.30573\n",
      "[233]\tvalidation_0-merror:0.29936\n",
      "[234]\tvalidation_0-merror:0.29936\n",
      "[235]\tvalidation_0-merror:0.30573\n",
      "[236]\tvalidation_0-merror:0.30573\n",
      "[237]\tvalidation_0-merror:0.30573\n",
      "[238]\tvalidation_0-merror:0.31847\n",
      "[239]\tvalidation_0-merror:0.31210\n",
      "[240]\tvalidation_0-merror:0.29936\n",
      "[241]\tvalidation_0-merror:0.30573\n",
      "[242]\tvalidation_0-merror:0.29936\n",
      "[243]\tvalidation_0-merror:0.29936\n",
      "[244]\tvalidation_0-merror:0.29936\n",
      "[245]\tvalidation_0-merror:0.28662\n",
      "[246]\tvalidation_0-merror:0.29299\n",
      "[247]\tvalidation_0-merror:0.29936\n",
      "[248]\tvalidation_0-merror:0.29299\n",
      "[249]\tvalidation_0-merror:0.29299\n",
      "[250]\tvalidation_0-merror:0.29299\n",
      "[251]\tvalidation_0-merror:0.30573\n",
      "[252]\tvalidation_0-merror:0.29936\n",
      "[253]\tvalidation_0-merror:0.29936\n",
      "[254]\tvalidation_0-merror:0.29936\n",
      "[255]\tvalidation_0-merror:0.29936\n",
      "[256]\tvalidation_0-merror:0.29936\n",
      "[257]\tvalidation_0-merror:0.29936\n",
      "[258]\tvalidation_0-merror:0.29936\n",
      "[259]\tvalidation_0-merror:0.29299\n",
      "[260]\tvalidation_0-merror:0.29936\n",
      "[261]\tvalidation_0-merror:0.28662\n",
      "[262]\tvalidation_0-merror:0.29936\n",
      "[263]\tvalidation_0-merror:0.29936\n",
      "[264]\tvalidation_0-merror:0.30573\n",
      "[265]\tvalidation_0-merror:0.30573\n",
      "[266]\tvalidation_0-merror:0.30573\n",
      "[267]\tvalidation_0-merror:0.29936\n",
      "[268]\tvalidation_0-merror:0.29299\n",
      "[269]\tvalidation_0-merror:0.28662\n",
      "[270]\tvalidation_0-merror:0.29936\n",
      "[271]\tvalidation_0-merror:0.29936\n",
      "[272]\tvalidation_0-merror:0.29936\n",
      "[273]\tvalidation_0-merror:0.29936\n",
      "[274]\tvalidation_0-merror:0.29936\n",
      "[275]\tvalidation_0-merror:0.29936\n",
      "[276]\tvalidation_0-merror:0.30573\n",
      "[277]\tvalidation_0-merror:0.29936\n",
      "[278]\tvalidation_0-merror:0.30573\n",
      "[279]\tvalidation_0-merror:0.29936\n",
      "[280]\tvalidation_0-merror:0.30573\n",
      "[281]\tvalidation_0-merror:0.29936\n",
      "[282]\tvalidation_0-merror:0.29936\n",
      "[283]\tvalidation_0-merror:0.31210\n",
      "[284]\tvalidation_0-merror:0.30573\n",
      "[285]\tvalidation_0-merror:0.29936\n",
      "[286]\tvalidation_0-merror:0.31210\n",
      "[287]\tvalidation_0-merror:0.30573\n",
      "[288]\tvalidation_0-merror:0.31210\n",
      "[289]\tvalidation_0-merror:0.30573\n",
      "[290]\tvalidation_0-merror:0.29936\n",
      "[291]\tvalidation_0-merror:0.30573\n",
      "[292]\tvalidation_0-merror:0.30573\n",
      "[293]\tvalidation_0-merror:0.29936\n",
      "[294]\tvalidation_0-merror:0.29936\n",
      "[295]\tvalidation_0-merror:0.30573\n",
      "[296]\tvalidation_0-merror:0.30573\n",
      "[297]\tvalidation_0-merror:0.30573\n",
      "[298]\tvalidation_0-merror:0.29936\n",
      "[299]\tvalidation_0-merror:0.30573\n",
      "[300]\tvalidation_0-merror:0.30573\n",
      "[301]\tvalidation_0-merror:0.30573\n",
      "[302]\tvalidation_0-merror:0.30573\n",
      "[303]\tvalidation_0-merror:0.30573\n",
      "[304]\tvalidation_0-merror:0.30573\n",
      "[305]\tvalidation_0-merror:0.30573\n",
      "[306]\tvalidation_0-merror:0.30573\n",
      "[307]\tvalidation_0-merror:0.30573\n",
      "[308]\tvalidation_0-merror:0.30573\n",
      "[309]\tvalidation_0-merror:0.30573\n",
      "[310]\tvalidation_0-merror:0.30573\n",
      "[311]\tvalidation_0-merror:0.30573\n",
      "[312]\tvalidation_0-merror:0.29936\n",
      "[313]\tvalidation_0-merror:0.30573\n",
      "[314]\tvalidation_0-merror:0.30573\n",
      "[315]\tvalidation_0-merror:0.30573\n",
      "[316]\tvalidation_0-merror:0.31210\n",
      "[317]\tvalidation_0-merror:0.31210\n",
      "[318]\tvalidation_0-merror:0.31210\n",
      "[319]\tvalidation_0-merror:0.31210\n",
      "[320]\tvalidation_0-merror:0.31210\n",
      "[321]\tvalidation_0-merror:0.31210\n",
      "[322]\tvalidation_0-merror:0.31210\n",
      "[323]\tvalidation_0-merror:0.30573\n",
      "[324]\tvalidation_0-merror:0.30573\n",
      "[325]\tvalidation_0-merror:0.30573\n",
      "[326]\tvalidation_0-merror:0.30573\n",
      "[327]\tvalidation_0-merror:0.31210\n",
      "[328]\tvalidation_0-merror:0.30573\n",
      "[329]\tvalidation_0-merror:0.30573\n",
      "[330]\tvalidation_0-merror:0.31847\n",
      "[331]\tvalidation_0-merror:0.31847\n",
      "[332]\tvalidation_0-merror:0.31847\n",
      "[333]\tvalidation_0-merror:0.31847\n",
      "[334]\tvalidation_0-merror:0.31210\n",
      "[335]\tvalidation_0-merror:0.31210\n",
      "[336]\tvalidation_0-merror:0.31210\n",
      "[337]\tvalidation_0-merror:0.31210\n",
      "[338]\tvalidation_0-merror:0.31210\n",
      "[339]\tvalidation_0-merror:0.31847\n",
      "[340]\tvalidation_0-merror:0.31210\n",
      "[341]\tvalidation_0-merror:0.31210\n",
      "[342]\tvalidation_0-merror:0.31210\n",
      "[343]\tvalidation_0-merror:0.31210\n",
      "[344]\tvalidation_0-merror:0.31210\n",
      "[345]\tvalidation_0-merror:0.31210\n",
      "[346]\tvalidation_0-merror:0.31210\n",
      "[347]\tvalidation_0-merror:0.31210\n",
      "[348]\tvalidation_0-merror:0.31210\n",
      "[349]\tvalidation_0-merror:0.31210\n",
      "[350]\tvalidation_0-merror:0.31210\n",
      "[351]\tvalidation_0-merror:0.31210\n",
      "[352]\tvalidation_0-merror:0.30573\n",
      "[353]\tvalidation_0-merror:0.30573\n",
      "[354]\tvalidation_0-merror:0.31210\n",
      "[355]\tvalidation_0-merror:0.31210\n",
      "[356]\tvalidation_0-merror:0.31210\n",
      "[357]\tvalidation_0-merror:0.31210\n",
      "[358]\tvalidation_0-merror:0.31210\n",
      "[359]\tvalidation_0-merror:0.31210\n",
      "[360]\tvalidation_0-merror:0.31210\n",
      "[361]\tvalidation_0-merror:0.31210\n",
      "[362]\tvalidation_0-merror:0.31847\n",
      "[363]\tvalidation_0-merror:0.31210\n",
      "[364]\tvalidation_0-merror:0.30573\n",
      "[365]\tvalidation_0-merror:0.29936\n",
      "[366]\tvalidation_0-merror:0.29936\n",
      "[367]\tvalidation_0-merror:0.30573\n",
      "[368]\tvalidation_0-merror:0.30573\n",
      "[369]\tvalidation_0-merror:0.31210\n",
      "[370]\tvalidation_0-merror:0.31210\n",
      "[371]\tvalidation_0-merror:0.30573\n",
      "[372]\tvalidation_0-merror:0.29936\n",
      "[373]\tvalidation_0-merror:0.29936\n",
      "[374]\tvalidation_0-merror:0.29936\n",
      "[375]\tvalidation_0-merror:0.31210\n",
      "[376]\tvalidation_0-merror:0.30573\n",
      "[377]\tvalidation_0-merror:0.30573\n",
      "[378]\tvalidation_0-merror:0.30573\n",
      "[379]\tvalidation_0-merror:0.30573\n",
      "[380]\tvalidation_0-merror:0.30573\n",
      "[381]\tvalidation_0-merror:0.29936\n",
      "[382]\tvalidation_0-merror:0.30573\n",
      "[383]\tvalidation_0-merror:0.31210\n",
      "[384]\tvalidation_0-merror:0.30573\n",
      "[385]\tvalidation_0-merror:0.30573\n",
      "[386]\tvalidation_0-merror:0.30573\n",
      "[387]\tvalidation_0-merror:0.30573\n",
      "[388]\tvalidation_0-merror:0.30573\n",
      "[389]\tvalidation_0-merror:0.30573\n",
      "[390]\tvalidation_0-merror:0.30573\n",
      "[391]\tvalidation_0-merror:0.29936\n",
      "[392]\tvalidation_0-merror:0.29299\n",
      "[393]\tvalidation_0-merror:0.29299\n",
      "[394]\tvalidation_0-merror:0.29299\n",
      "[395]\tvalidation_0-merror:0.29299\n",
      "[396]\tvalidation_0-merror:0.29936\n",
      "[397]\tvalidation_0-merror:0.29299\n",
      "[398]\tvalidation_0-merror:0.29299\n",
      "[399]\tvalidation_0-merror:0.29936\n",
      "[400]\tvalidation_0-merror:0.29936\n",
      "[401]\tvalidation_0-merror:0.29936\n",
      "[402]\tvalidation_0-merror:0.29936\n",
      "[403]\tvalidation_0-merror:0.30573\n",
      "[404]\tvalidation_0-merror:0.30573\n",
      "[405]\tvalidation_0-merror:0.31210\n",
      "[406]\tvalidation_0-merror:0.30573\n",
      "[407]\tvalidation_0-merror:0.30573\n",
      "[408]\tvalidation_0-merror:0.30573\n",
      "[409]\tvalidation_0-merror:0.29936\n",
      "[410]\tvalidation_0-merror:0.30573\n",
      "[411]\tvalidation_0-merror:0.30573\n",
      "[412]\tvalidation_0-merror:0.30573\n",
      "[413]\tvalidation_0-merror:0.30573\n",
      "[414]\tvalidation_0-merror:0.30573\n",
      "[415]\tvalidation_0-merror:0.30573\n",
      "[416]\tvalidation_0-merror:0.29936\n",
      "[417]\tvalidation_0-merror:0.29936\n",
      "[418]\tvalidation_0-merror:0.29936\n",
      "[419]\tvalidation_0-merror:0.29936\n",
      "[420]\tvalidation_0-merror:0.28662\n",
      "[421]\tvalidation_0-merror:0.29299\n",
      "[422]\tvalidation_0-merror:0.29936\n",
      "[423]\tvalidation_0-merror:0.29936\n",
      "[424]\tvalidation_0-merror:0.30573\n",
      "[425]\tvalidation_0-merror:0.29936\n",
      "[426]\tvalidation_0-merror:0.30573\n",
      "[427]\tvalidation_0-merror:0.30573\n",
      "[428]\tvalidation_0-merror:0.29299\n",
      "[429]\tvalidation_0-merror:0.29299\n",
      "[430]\tvalidation_0-merror:0.29299\n",
      "[431]\tvalidation_0-merror:0.29299\n",
      "[432]\tvalidation_0-merror:0.30573\n",
      "[433]\tvalidation_0-merror:0.30573\n",
      "[434]\tvalidation_0-merror:0.29936\n",
      "[435]\tvalidation_0-merror:0.30573\n",
      "[436]\tvalidation_0-merror:0.30573\n",
      "[437]\tvalidation_0-merror:0.30573\n",
      "[438]\tvalidation_0-merror:0.29936\n",
      "[439]\tvalidation_0-merror:0.30573\n",
      "[440]\tvalidation_0-merror:0.30573\n",
      "[441]\tvalidation_0-merror:0.30573\n",
      "[442]\tvalidation_0-merror:0.30573\n",
      "[443]\tvalidation_0-merror:0.30573\n",
      "[444]\tvalidation_0-merror:0.29936\n",
      "[445]\tvalidation_0-merror:0.30573\n",
      "[446]\tvalidation_0-merror:0.30573\n",
      "[447]\tvalidation_0-merror:0.30573\n",
      "[448]\tvalidation_0-merror:0.30573\n",
      "[449]\tvalidation_0-merror:0.30573\n",
      "[450]\tvalidation_0-merror:0.30573\n",
      "[451]\tvalidation_0-merror:0.29936\n",
      "[452]\tvalidation_0-merror:0.29936\n",
      "[453]\tvalidation_0-merror:0.29936\n",
      "[454]\tvalidation_0-merror:0.29936\n",
      "[455]\tvalidation_0-merror:0.29936\n",
      "[456]\tvalidation_0-merror:0.29299\n",
      "[457]\tvalidation_0-merror:0.29299\n",
      "[458]\tvalidation_0-merror:0.29299\n",
      "[459]\tvalidation_0-merror:0.29299\n",
      "[460]\tvalidation_0-merror:0.29299\n",
      "[461]\tvalidation_0-merror:0.29299\n",
      "[462]\tvalidation_0-merror:0.29299\n",
      "[463]\tvalidation_0-merror:0.29299\n",
      "[464]\tvalidation_0-merror:0.29299\n",
      "[465]\tvalidation_0-merror:0.29299\n",
      "[466]\tvalidation_0-merror:0.29299\n",
      "[467]\tvalidation_0-merror:0.29299\n",
      "[468]\tvalidation_0-merror:0.29299\n",
      "[469]\tvalidation_0-merror:0.29299\n",
      "[470]\tvalidation_0-merror:0.29299\n",
      "[471]\tvalidation_0-merror:0.29299\n",
      "[472]\tvalidation_0-merror:0.29936\n",
      "[473]\tvalidation_0-merror:0.29936\n",
      "[474]\tvalidation_0-merror:0.29936\n",
      "[475]\tvalidation_0-merror:0.29936\n",
      "[476]\tvalidation_0-merror:0.29299\n",
      "[477]\tvalidation_0-merror:0.29299\n",
      "[478]\tvalidation_0-merror:0.29299\n",
      "[479]\tvalidation_0-merror:0.29936\n",
      "[480]\tvalidation_0-merror:0.28662\n",
      "[481]\tvalidation_0-merror:0.29299\n",
      "[482]\tvalidation_0-merror:0.29299\n",
      "[483]\tvalidation_0-merror:0.29936\n",
      "[484]\tvalidation_0-merror:0.29936\n",
      "[485]\tvalidation_0-merror:0.28025\n",
      "[486]\tvalidation_0-merror:0.29299\n",
      "[487]\tvalidation_0-merror:0.29299\n",
      "[488]\tvalidation_0-merror:0.29299\n",
      "[489]\tvalidation_0-merror:0.28662\n",
      "[490]\tvalidation_0-merror:0.28662\n",
      "[491]\tvalidation_0-merror:0.28662\n",
      "[492]\tvalidation_0-merror:0.28662\n",
      "[493]\tvalidation_0-merror:0.28025\n",
      "[494]\tvalidation_0-merror:0.28025\n",
      "[495]\tvalidation_0-merror:0.28025\n",
      "[496]\tvalidation_0-merror:0.28025\n",
      "[497]\tvalidation_0-merror:0.28025\n",
      "[498]\tvalidation_0-merror:0.28025\n"
     ]
    }
   ],
   "source": [
    "best_xgb.fit(X_train_all, y_train_all,eval_set= [(X_val_all,y_val_all)],verbose=1)\n",
    "\n",
    "# Now you can use best_model to make predictions\n",
    "y_pred = best_xgb.predict(X_val_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    battery issue       0.12      0.20      0.15         5\n",
      "             bmis       1.00      0.50      0.67         2\n",
      "      cable issue       0.74      0.82      0.78        17\n",
      "data access issue       0.71      0.71      0.71        14\n",
      "decision accuracy       0.33      0.60      0.43         5\n",
      "    display issue       1.00      0.33      0.50         3\n",
      "        fan issue       0.75      0.43      0.55         7\n",
      "          freezes       0.75      0.60      0.67         5\n",
      "   hardware issue       0.40      0.33      0.36         6\n",
      "       no details       0.75      1.00      0.86        12\n",
      "      power issue       0.50      0.50      0.50         4\n",
      "        shuts off       1.00      0.25      0.40         4\n",
      "   software issue       0.40      0.40      0.40         5\n",
      "temp sensor error       1.00      0.67      0.80         3\n",
      "    testing issue       1.00      0.25      0.40         4\n",
      "    update issues       0.88      0.90      0.89        41\n",
      "         vin scan       0.71      0.71      0.71         7\n",
      "      wifi issues       0.93      1.00      0.96        13\n",
      "\n",
      "         accuracy                           0.72       157\n",
      "        macro avg       0.72      0.57      0.60       157\n",
      "     weighted avg       0.75      0.72      0.72       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val_all,y_pred,target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Now you can use best_model to make predictions\n",
    "y_pred_test = best_xgb.predict(X_test_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    battery issue       1.00      0.80      0.89         5\n",
      "             bmis       0.50      0.50      0.50         2\n",
      "      cable issue       0.67      0.82      0.74        17\n",
      "data access issue       0.67      0.67      0.67        15\n",
      "decision accuracy       0.25      0.20      0.22         5\n",
      "    display issue       0.50      0.50      0.50         2\n",
      "        fan issue       0.80      0.57      0.67         7\n",
      "          freezes       0.20      0.17      0.18         6\n",
      "   hardware issue       0.20      0.17      0.18         6\n",
      "       no details       0.79      0.85      0.81        13\n",
      "      power issue       1.00      0.25      0.40         4\n",
      "        shuts off       0.40      0.50      0.44         4\n",
      "   software issue       0.00      0.00      0.00         4\n",
      "temp sensor error       1.00      0.50      0.67         2\n",
      "    testing issue       1.00      0.67      0.80         3\n",
      "    update issues       0.87      0.98      0.92        41\n",
      "         vin scan       0.64      0.88      0.74         8\n",
      "      wifi issues       1.00      0.86      0.92        14\n",
      "\n",
      "         accuracy                           0.72       158\n",
      "        macro avg       0.64      0.55      0.57       158\n",
      "     weighted avg       0.72      0.72      0.70       158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_all,y_pred_test,target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Method (OpenAI Some)\n",
    "\n",
    "After trying to improve the xgboost model with other xgboost models, I saw that perfomrance did not go up significantlly. After doing more research on text embeddings and classificaiton models for text, I learned that xgboost models are not capable of understanding the full information encoded by transoformer embeddings (OpenAI Embeddings). Instead, models like GPT, BERT are able to understand complex relationships between words/characters, by using deep learning models. The following cells explore the classificaiton performanc of deep learning on OpenAI's embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into testing and training data set. Set the testing size to 30% and stratify the data on y\n",
    "X_train_some, X_temp_some, y_train_some, y_temp_some = train_test_split (X_openai_some,y,stratify = y, random_state=42,test_size=.30)\n",
    "## Training neural networks, and optimizing hyperparameters can be imporved by providing a validation set \n",
    "X_val_some, X_test_some, y_val_some, y_test_some = train_test_split (X_temp_some,y_temp_some,stratify = y_temp_some, random_state=42,test_size=.50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# One-hot encode the labels\n",
    "y_train_encoded = to_categorical(y_train_some)\n",
    "y_val_encoded = to_categorical(y_val_some)\n",
    "y_test_encoded = to_categorical(y_test_some)\n",
    "\n",
    "#Convert X's to Tensors\n",
    "X_train_tensor = tf.constant(X_train_some, dtype=tf.float32)\n",
    "X_val_tensor = tf.constant(X_val_some, dtype=tf.float32)\n",
    "X_test_tensor = tf.constant(X_test_some, dtype=tf.float32)\n",
    "\n",
    "# Convert y's to TensorFlow tensors\n",
    "y_train_tensor = tf.constant(y_train_encoded, dtype=tf.float32)\n",
    "y_val_tensor = tf.constant(y_val_encoded, dtype=tf.float32)\n",
    "y_test_tensor = tf.constant(y_test_encoded, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced',classes= np.unique(y_train_some), y=y_train_some)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters to tune\n",
    "    optimizer_name = trial.suggest_categorical('optimizer_name', ['adam', 'adamax', 'nadam'])\n",
    "\n",
    "    if optimizer_name == 'sgd':\n",
    "        learning_rate = trial.suggest_float('sgd_learning_rate', 1e-6, 1e-2)\n",
    "        optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=learning_rate)\n",
    "    elif optimizer_name == 'sgd_with_momentum':\n",
    "        learning_rate = trial.suggest_float('momentum_learning_rate', 1e-6, 1e-2)\n",
    "        momentum = trial.suggest_float('momentum_momentum', 0.1, 0.9)\n",
    "        optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=learning_rate, momentum=momentum)\n",
    "    elif optimizer_name == 'rmsprop':\n",
    "        learning_rate = trial.suggest_float('rmsprop_learning_rate', 1e-6, 1e-2)\n",
    "        rho = trial.suggest_float('rmsprop_rho', 0.1, 0.9)\n",
    "        optimizer = tf.keras.optimizers.legacy.RMSprop(learning_rate=learning_rate, rho=rho)\n",
    "    elif optimizer_name == 'adam':\n",
    "        learning_rate = trial.suggest_float('adam_learning_rate', 1e-6, 1e-2)\n",
    "        beta_1 = trial.suggest_float('adam_beta_1', 0.8, 0.99)\n",
    "        beta_2 = trial.suggest_float('adam_beta_2', 0.9, 0.9999)\n",
    "        optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate, beta_1=beta_1, beta_2=beta_2)\n",
    "    elif optimizer_name == 'adamax':\n",
    "        learning_rate = trial.suggest_float('adamax_learning_rate', 1e-6, 1e-2)\n",
    "        beta_1 = trial.suggest_float('adamax_beta_1', 0.8, 0.99)\n",
    "        beta_2 = trial.suggest_float('adamax_beta_2', 0.9, 0.9999)\n",
    "        optimizer = tf.keras.optimizers.legacy.Adamax(learning_rate=learning_rate, beta_1=beta_1, beta_2=beta_2)\n",
    "    elif optimizer_name == 'nadam':\n",
    "        learning_rate = trial.suggest_float('nadam_learning_rate', 1e-6, 1e-2)\n",
    "        beta_1 = trial.suggest_float('nadam_beta_1', 0.8, 0.99)\n",
    "        beta_2 = trial.suggest_float('nadam_beta_2', 0.9, 0.9999)\n",
    "        optimizer = tf.keras.optimizers.legacy.Nadam(learning_rate=learning_rate, beta_1=beta_1, beta_2=beta_2)\n",
    "\n",
    "        \n",
    "        '''{'dropout_rate': 0.10921940617643529,\n",
    " 'learning_rate': 0.0004922542982014772,\n",
    " 'dense_units': 762,\n",
    " 'l2_regularization_exp': -5.378788139919697,\n",
    " 'l1_regularization_exp': -5.325881561279877,\n",
    " 'epochs': 26,\n",
    " 'batch_size': 16,\n",
    " 'weight_initializer': 'random_uniform',\n",
    " 'activation_function': 'relu'}'''\n",
    "    \n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 1)\n",
    "    dropout_rate2 = trial.suggest_float('dropout_rate2', 0.1, 1)\n",
    "    dense_units = trial.suggest_int('dense_units', 8, 1024)\n",
    "    l2_regularization_exp = trial.suggest_float('l2_regularization_exp', -6, 1)\n",
    "    l1_regularization_exp = trial.suggest_float('l1_regularization_exp', -6, 1)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [4,8,16,32, 64, 128, 256])\n",
    "    weight_initializer = trial.suggest_categorical('weight_initializer', ['random_uniform', 'random_normal', 'glorot_uniform'])\n",
    "    activation_function = trial.suggest_categorical('activation_function', ['relu', 'sigmoid', 'tanh','leaky_relu'])\n",
    "    epochs = trial.suggest_int('epochs',5,40)\n",
    "\n",
    "\n",
    "    # Calculate l2_regularization from the exponent\n",
    "    l2_regularization = math.pow(10, l2_regularization_exp)\n",
    "    l1_regularization = math.pow(10, l1_regularization_exp)\n",
    "\n",
    "    \n",
    "    # Define the model\n",
    "    def create_model():\n",
    "        model = Sequential()\n",
    "        model.add(Dense(dense_units, input_dim=1536, \n",
    "                        kernel_regularizer=tf.keras.regularizers.l1_l2(l1=l1_regularization, l2=l2_regularization),\n",
    "                        kernel_initializer=weight_initializer))\n",
    "        model.add(Dropout(dropout_rate2))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(LeakyReLU() if activation_function == 'leaky_relu' else Activation(activation_function))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dense(18, activation='softmax'))\n",
    "        return model\n",
    "\n",
    "    # Create the model inside the objective function to avoid TensorFlow retracing warning\n",
    "    model = create_model()\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=optimizer, metrics=[tf.keras.metrics.F1Score('weighted')])\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor='val_f1_score')\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train_tensor, y_train_tensor, validation_data=(X_val_tensor, y_val_tensor),\n",
    "              epochs=epochs, batch_size=batch_size, callbacks=[lr_scheduler,TFKerasPruningCallback(trial, 'val_f1_score')],\n",
    "              verbose=0,workers = 1,class_weight=class_weights)\n",
    "\n",
    "    # Predict the classes on the validation data\n",
    "    y_pred = model.predict(X_val_tensor)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # Calculate the weighted F1-score\n",
    "    f1 = f1_score(y_val_some, y_pred_classes, average='weighted')\n",
    "\n",
    "    return f1\n",
    "\n",
    "# Create an Optuna study and optimize the objective function \n",
    "study = optuna.create_study(direction='maximize', pruner=optuna.pruners.HyperbandPruner(min_resource = 20))\n",
    "study.optimize(objective, n_trials=300, n_jobs= 8,show_progress_bar=True)  # Set n_jobs=1 to avoid the TensorFlow retracing warning\n",
    "\n",
    "# Print the best hyperparameters and the corresponding accuracy\n",
    "best_params = study.best_params\n",
    "best_f1 = study.best_value\n",
    "\n",
    "# Print the best hyperparameters and the corresponding accuracy\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best F1-Score:\", best_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best Neural Network Parameters\n",
    "{\n",
    " 'optimizer_name': 'adam',\n",
    " 'learning_rate': 7.322790338548657e-07,\n",
    " 'beta_1': 0.9446718096733093,\n",
    " 'beta_2': 0.900862991809845,\n",
    " 'dropout_rate': 0.11800425769664818, \n",
    " 'dropout_rate2': 0.564894261824532,\n",
    " 'learning_rate': 'Not provided in the configuration',\n",
    " 'dense_units': 125,\n",
    " 'l2_regularization_exp': 6.953548108867835e-06,\n",
    " 'l1_regularization_exp': 1.0231772193947108e-06,\n",
    " 'epochs': 26,\n",
    " 'batch_size': 16,\n",
    " 'weight_initializer': 'random_normal',\n",
    " 'activation_function': 'sigmoid'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 2.9831 - f1_score: 0.2347 - val_loss: 2.4919 - val_f1_score: 0.1082 - lr: 0.0073\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2.1401 - f1_score: 0.3837 - val_loss: 2.3001 - val_f1_score: 0.1082 - lr: 0.0073\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.7378 - f1_score: 0.4827 - val_loss: 2.1678 - val_f1_score: 0.1625 - lr: 0.0073\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.4276 - f1_score: 0.5592 - val_loss: 1.9678 - val_f1_score: 0.2421 - lr: 0.0073\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1.1754 - f1_score: 0.6152 - val_loss: 1.7687 - val_f1_score: 0.3734 - lr: 0.0073\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1.0187 - f1_score: 0.6603 - val_loss: 1.5845 - val_f1_score: 0.5049 - lr: 0.0073\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8555 - f1_score: 0.7150 - val_loss: 1.4180 - val_f1_score: 0.6110 - lr: 0.0073\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.8180 - f1_score: 0.7242 - val_loss: 1.3433 - val_f1_score: 0.5618 - lr: 0.0073\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.7057 - f1_score: 0.7429 - val_loss: 1.3309 - val_f1_score: 0.5622 - lr: 0.0073\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6830 - f1_score: 0.7540 - val_loss: 1.1763 - val_f1_score: 0.6440 - lr: 0.0073\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6002 - f1_score: 0.7734 - val_loss: 1.2225 - val_f1_score: 0.6049 - lr: 0.0073\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5843 - f1_score: 0.7939 - val_loss: 1.1467 - val_f1_score: 0.6372 - lr: 7.3228e-04\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4596 - f1_score: 0.8386 - val_loss: 1.0919 - val_f1_score: 0.6801 - lr: 7.3228e-04\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4925 - f1_score: 0.8193 - val_loss: 1.0790 - val_f1_score: 0.7442 - lr: 7.3228e-04\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4394 - f1_score: 0.8414 - val_loss: 1.0749 - val_f1_score: 0.7346 - lr: 7.3228e-04\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4183 - f1_score: 0.8610 - val_loss: 1.0618 - val_f1_score: 0.7340 - lr: 7.3228e-04\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4441 - f1_score: 0.8328 - val_loss: 1.0595 - val_f1_score: 0.7327 - lr: 7.3228e-04\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4140 - f1_score: 0.8701 - val_loss: 1.0748 - val_f1_score: 0.7348 - lr: 7.3228e-04\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3917 - f1_score: 0.8585 - val_loss: 1.0884 - val_f1_score: 0.7348 - lr: 7.3228e-04\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3871 - f1_score: 0.8581 - val_loss: 1.1118 - val_f1_score: 0.7271 - lr: 7.3228e-04\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3729 - f1_score: 0.8542 - val_loss: 1.1321 - val_f1_score: 0.7214 - lr: 7.3228e-04\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3900 - f1_score: 0.8717 - val_loss: 1.1374 - val_f1_score: 0.7219 - lr: 7.3228e-05\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3543 - f1_score: 0.8759 - val_loss: 1.1410 - val_f1_score: 0.7223 - lr: 7.3228e-05\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3587 - f1_score: 0.8890 - val_loss: 1.1446 - val_f1_score: 0.7289 - lr: 7.3228e-05\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3329 - f1_score: 0.8816 - val_loss: 1.1497 - val_f1_score: 0.7289 - lr: 7.3228e-05\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3641 - f1_score: 0.8721 - val_loss: 1.1541 - val_f1_score: 0.7355 - lr: 7.3228e-05\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3419 - f1_score: 0.8823 - val_loss: 1.1557 - val_f1_score: 0.7355 - lr: 7.3228e-05\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3302 - f1_score: 0.8889 - val_loss: 1.1577 - val_f1_score: 0.7355 - lr: 7.3228e-05\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3957 - f1_score: 0.8508 - val_loss: 1.1610 - val_f1_score: 0.7355 - lr: 7.3228e-05\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3911 - f1_score: 0.8641 - val_loss: 1.1622 - val_f1_score: 0.7412 - lr: 7.3228e-05\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3364 - f1_score: 0.8833 - val_loss: 1.1636 - val_f1_score: 0.7412 - lr: 7.3228e-05\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3845 - f1_score: 0.8742 - val_loss: 1.1647 - val_f1_score: 0.7421 - lr: 7.3228e-06\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3321 - f1_score: 0.8839 - val_loss: 1.1652 - val_f1_score: 0.7421 - lr: 7.3228e-06\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3532 - f1_score: 0.8795 - val_loss: 1.1650 - val_f1_score: 0.7351 - lr: 7.3228e-06\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3849 - f1_score: 0.8588 - val_loss: 1.1647 - val_f1_score: 0.7351 - lr: 7.3228e-06\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3926 - f1_score: 0.8765 - val_loss: 1.1671 - val_f1_score: 0.7351 - lr: 7.3228e-06\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3144 - f1_score: 0.8762 - val_loss: 1.1675 - val_f1_score: 0.7351 - lr: 7.3228e-06\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3213 - f1_score: 0.8889 - val_loss: 1.1679 - val_f1_score: 0.7351 - lr: 7.3228e-06\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3370 - f1_score: 0.8880 - val_loss: 1.1683 - val_f1_score: 0.7421 - lr: 7.3228e-06\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3337 - f1_score: 0.8731 - val_loss: 1.1681 - val_f1_score: 0.7421 - lr: 7.3228e-06\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3285 - f1_score: 0.8745 - val_loss: 1.1703 - val_f1_score: 0.7421 - lr: 7.3228e-06\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3681 - f1_score: 0.8864 - val_loss: 1.1697 - val_f1_score: 0.7421 - lr: 7.3228e-07\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3167 - f1_score: 0.8693 - val_loss: 1.1697 - val_f1_score: 0.7416 - lr: 7.3228e-07\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3564 - f1_score: 0.8871 - val_loss: 1.1702 - val_f1_score: 0.7416 - lr: 7.3228e-07\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3307 - f1_score: 0.8844 - val_loss: 1.1691 - val_f1_score: 0.7421 - lr: 7.3228e-07\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3564 - f1_score: 0.8827 - val_loss: 1.1679 - val_f1_score: 0.7421 - lr: 7.3228e-07\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3795 - f1_score: 0.8715 - val_loss: 1.1676 - val_f1_score: 0.7421 - lr: 7.3228e-07\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3629 - f1_score: 0.8817 - val_loss: 1.1678 - val_f1_score: 0.7421 - lr: 7.3228e-07\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4000 - f1_score: 0.8644 - val_loss: 1.1681 - val_f1_score: 0.7421 - lr: 7.3228e-07\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3679 - f1_score: 0.8508 - val_loss: 1.1684 - val_f1_score: 0.7421 - lr: 7.3228e-07\n",
      "Test F1_Score:  0.7496675252914429\n"
     ]
    }
   ],
   "source": [
    "def create_best_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(best_params['dense_units'], input_dim=1536, \n",
    "                    kernel_regularizer=tf.keras.regularizers.l1_l2(l1=math.pow(10, best_params['l1_regularization_exp']), \n",
    "                                                                  l2=math.pow(10, best_params['l2_regularization_exp'])),\n",
    "                    kernel_initializer=best_params['weight_initializer']))\n",
    "    model.add(Dropout(best_params['dropout_rate']))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU() if best_params['activation_function'] == 'leaky_relu' else Activation(best_params['activation_function']))\n",
    "    model.add(Dropout(best_params['dropout_rate2']))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(18, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# Create the best model\n",
    "best_optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=best_params['adam_learning_rate'], beta_1=best_params['adam_beta_1'], beta_2=best_params['adam_beta_2'])\n",
    "best_model = create_best_model()\n",
    "\n",
    "best_model.compile(loss='categorical_crossentropy', optimizer=best_optimizer, metrics=[tf.keras.metrics.F1Score('weighted')])\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_f1_score')\n",
    "\n",
    "# Train the best model\n",
    "best_model.fit(X_train_some, y_train_encoded, validation_data=(X_val_some, y_val_encoded),\n",
    "          epochs=50, batch_size=best_params['batch_size'], callbacks=[lr_scheduler],\n",
    "          verbose=1,workers = 8,class_weight=class_weights)\n",
    "\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "_, f1 = best_model.evaluate(X_test_some, y_test_encoded, verbose=0)\n",
    "print(\"Test F1_Score: \", f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: nn5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: nn5/assets\n"
     ]
    }
   ],
   "source": [
    "best_model.save('best_neural_network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    battery issue       0.17      0.20      0.18         5\n",
      "             bmis       0.25      0.50      0.33         2\n",
      "      cable issue       0.81      0.76      0.79        17\n",
      "data access issue       0.69      0.64      0.67        14\n",
      "decision accuracy       0.45      1.00      0.62         5\n",
      "    display issue       0.75      1.00      0.86         3\n",
      "        fan issue       0.71      0.71      0.71         7\n",
      "          freezes       0.75      0.60      0.67         5\n",
      "   hardware issue       0.50      0.67      0.57         6\n",
      "       no details       0.92      1.00      0.96        12\n",
      "      power issue       1.00      0.50      0.67         4\n",
      "        shuts off       1.00      0.25      0.40         4\n",
      "   software issue       0.20      0.20      0.20         5\n",
      "temp sensor error       1.00      0.67      0.80         3\n",
      "    testing issue       0.67      0.50      0.57         4\n",
      "    update issues       0.94      0.80      0.87        41\n",
      "         vin scan       0.75      0.86      0.80         7\n",
      "      wifi issues       0.87      1.00      0.93        13\n",
      "\n",
      "         accuracy                           0.74       157\n",
      "        macro avg       0.69      0.66      0.64       157\n",
      "     weighted avg       0.78      0.74      0.74       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have trained and evaluated your model on the test dataset\n",
    "y_pred = best_model.predict(X_val_some)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Generate the classification report\n",
    "classification_rep = classification_report(y_val_some, y_pred_classes, target_names=target_names)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to disk\n",
    "# best_model.save('best_neural_network')\n",
    "\n",
    "# Load the model from disk\n",
    "loaded_model = tf.keras.models.load_model('best_neural_network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    battery issue       0.17      0.20      0.18         5\n",
      "             bmis       0.25      0.50      0.33         2\n",
      "      cable issue       0.81      0.76      0.79        17\n",
      "data access issue       0.69      0.64      0.67        14\n",
      "decision accuracy       0.45      1.00      0.62         5\n",
      "    display issue       0.75      1.00      0.86         3\n",
      "        fan issue       0.71      0.71      0.71         7\n",
      "          freezes       0.75      0.60      0.67         5\n",
      "   hardware issue       0.50      0.67      0.57         6\n",
      "       no details       0.92      1.00      0.96        12\n",
      "      power issue       1.00      0.50      0.67         4\n",
      "        shuts off       1.00      0.25      0.40         4\n",
      "   software issue       0.20      0.20      0.20         5\n",
      "temp sensor error       1.00      0.67      0.80         3\n",
      "    testing issue       0.67      0.50      0.57         4\n",
      "    update issues       0.94      0.80      0.87        41\n",
      "         vin scan       0.75      0.86      0.80         7\n",
      "      wifi issues       0.87      1.00      0.93        13\n",
      "\n",
      "         accuracy                           0.74       157\n",
      "        macro avg       0.69      0.66      0.64       157\n",
      "     weighted avg       0.78      0.74      0.74       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming you have trained and evaluated your model on the test dataset\n",
    "y_pred = loaded_model.predict(X_val_some)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Generate the classification report\n",
    "target_names = le.classes_  # Replace with your actual class names\n",
    "classification_rep = classification_report(y_val_some, y_pred_classes, target_names=target_names)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Adam',\n",
       " 'learning_rate': 7.322790338548657e-07,\n",
       " 'decay': 0.0,\n",
       " 'beta_1': 0.9446718096733093,\n",
       " 'beta_2': 0.900862991809845,\n",
       " 'epsilon': 1e-07,\n",
       " 'amsgrad': False}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.optimizer.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on more CPX data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_descriptions = pd.read_excel('CPX RMA Data 2022-2023.xlsx')[['Customer Reason']].copy()\n",
    "new_descriptions.columns = ['New_Description']\n",
    "new_descriptions['New_Description'] = new_descriptions['New_Description'].astype(str)\n",
    "new_descriptions = new_descriptions.dropna().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess New Description and apply Embedding\n",
    "\n",
    "\n",
    "'''new_descriptions['New_Processed_Description'] = new_descriptions['New_Description'].apply(preprocess_text)\n",
    "new_desc_embeddings = new_descriptions['New_Processed_Description'].apply(create_embedding)\n",
    "new_descriptions['Embedding'] = new_desc_embeddings\n",
    "new_descriptions.to_csv('Processed_CPX_2022_2023.csv',index = False)'''\n",
    "\n",
    "new_descriptions=pd.read_csv('Processed_CPX_2022_2023.csv')['New_Description'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_embedded_descriptions = pd.read_csv('Processed_CPX_2022_2023.csv')[['Embedding']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_embedding_matrix = np.stack(new_embedded_descriptions.Embedding.apply(eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_embeddings = normalize(new_embedding_matrix, norm='l2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = loaded_model.predict(X_new_embeddings)\n",
    "y_pred_classes = np.argmax(y_pred_proba, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = le.inverse_transform(y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_description_results = pd.DataFrame(new_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_description_results['Predicted_Category'] = predicted_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all, X_temp_all, y_train_all, y_temp_all = train_test_split (X_tfidf_all,y,stratify = y, random_state=42,test_size=.30)\n",
    "X_val_all, X_test_all, y_val_all, y_test_all = train_test_split(X_temp_all,y_temp_all, stratify=y_temp_all, random_state=42, test_size=.50)\n",
    "\n",
    "#Split data into testing and training data set. Set the testing size to 30% and stratify the data on y\n",
    "X_train_some, X_temp_some, y_train_some, y_temp_some = train_test_split (X_openai_some,y,stratify = y, random_state=42,test_size=.30)\n",
    "## Training neural networks, and optimizing hyperparameters can be imporved by providing a validation set \n",
    "X_val_some, X_test_some, y_val_some, y_test_some = train_test_split (X_temp_some,y_temp_some,stratify = y_temp_some, random_state=42,test_size=.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_some.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb = XGBClassifier(**best_xgb_params,eval_metric='mlogloss', objective='multi:softprob', tree_method='hist',n_jobs = -1,random_state = 42)\n",
    "\n",
    "best_xgb.fit(X_train_all, y_train_all)\n",
    "\n",
    "y_proba_xgb = best_xgb.predict_proba(X_val_all)\n",
    "y_pred_xgb = best_xgb.predict(X_val_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    battery issue       0.12      0.20      0.15         5\n",
      "             bmis       1.00      0.50      0.67         2\n",
      "      cable issue       0.74      0.82      0.78        17\n",
      "data access issue       0.71      0.71      0.71        14\n",
      "decision accuracy       0.33      0.60      0.43         5\n",
      "    display issue       1.00      0.33      0.50         3\n",
      "        fan issue       0.75      0.43      0.55         7\n",
      "          freezes       0.75      0.60      0.67         5\n",
      "   hardware issue       0.40      0.33      0.36         6\n",
      "       no details       0.75      1.00      0.86        12\n",
      "      power issue       0.50      0.50      0.50         4\n",
      "        shuts off       1.00      0.25      0.40         4\n",
      "   software issue       0.40      0.40      0.40         5\n",
      "temp sensor error       1.00      0.67      0.80         3\n",
      "    testing issue       1.00      0.25      0.40         4\n",
      "    update issues       0.88      0.90      0.89        41\n",
      "         vin scan       0.71      0.71      0.71         7\n",
      "      wifi issues       0.93      1.00      0.96        13\n",
      "\n",
      "         accuracy                           0.72       157\n",
      "        macro avg       0.72      0.57      0.60       157\n",
      "     weighted avg       0.75      0.72      0.72       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = le.classes_  # Replace with your actual class names\n",
    "print(classification_report(y_val_all, y_pred_xgb,target_names = le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    battery issue       1.00      0.80      0.89         5\n",
      "             bmis       0.50      0.50      0.50         2\n",
      "      cable issue       0.67      0.82      0.74        17\n",
      "data access issue       0.67      0.67      0.67        15\n",
      "decision accuracy       0.25      0.20      0.22         5\n",
      "    display issue       0.50      0.50      0.50         2\n",
      "        fan issue       0.80      0.57      0.67         7\n",
      "          freezes       0.20      0.17      0.18         6\n",
      "   hardware issue       0.20      0.17      0.18         6\n",
      "       no details       0.79      0.85      0.81        13\n",
      "      power issue       1.00      0.25      0.40         4\n",
      "        shuts off       0.40      0.50      0.44         4\n",
      "   software issue       0.00      0.00      0.00         4\n",
      "temp sensor error       1.00      0.50      0.67         2\n",
      "    testing issue       1.00      0.67      0.80         3\n",
      "    update issues       0.87      0.98      0.92        41\n",
      "         vin scan       0.64      0.88      0.74         8\n",
      "      wifi issues       1.00      0.86      0.92        14\n",
      "\n",
      "         accuracy                           0.72       158\n",
      "        macro avg       0.64      0.55      0.57       158\n",
      "     weighted avg       0.72      0.72      0.70       158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_proba_xgb_test = best_xgb.predict_proba(X_test_all)\n",
    "y_pred_xgb_test = best_xgb.predict(X_test_all)\n",
    "print(classification_report(y_test_all, y_pred_xgb_test,target_names = le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from disk\n",
    "loaded_model = tf.keras.models.load_model('best_neural_network')\n",
    "loaded_model2 = tf.keras.models.load_model('nn4')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 723us/step\n",
      "5/5 [==============================] - 0s 793us/step\n",
      "Validation Performance:\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    battery issue       0.17      0.20      0.18         5\n",
      "             bmis       0.25      0.50      0.33         2\n",
      "      cable issue       0.81      0.76      0.79        17\n",
      "data access issue       0.69      0.64      0.67        14\n",
      "decision accuracy       0.45      1.00      0.62         5\n",
      "    display issue       0.75      1.00      0.86         3\n",
      "        fan issue       0.71      0.71      0.71         7\n",
      "          freezes       0.75      0.60      0.67         5\n",
      "   hardware issue       0.50      0.67      0.57         6\n",
      "       no details       0.92      1.00      0.96        12\n",
      "      power issue       1.00      0.50      0.67         4\n",
      "        shuts off       1.00      0.25      0.40         4\n",
      "   software issue       0.20      0.20      0.20         5\n",
      "temp sensor error       1.00      0.67      0.80         3\n",
      "    testing issue       0.67      0.50      0.57         4\n",
      "    update issues       0.94      0.80      0.87        41\n",
      "         vin scan       0.75      0.86      0.80         7\n",
      "      wifi issues       0.87      1.00      0.93        13\n",
      "\n",
      "         accuracy                           0.74       157\n",
      "        macro avg       0.69      0.66      0.64       157\n",
      "     weighted avg       0.78      0.74      0.74       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##Best DL Model\n",
    "y_proba_dlv = loaded_model.predict(X_val_some)\n",
    "y_pred_dlv = np.argmax(y_proba_dlv, axis=1)\n",
    "\n",
    "##Second Best DL Model\n",
    "y_proba_dlv2 = loaded_model2.predict(X_val_some)\n",
    "y_pred_dlv2 = np.argmax(y_proba_dlv2, axis=1)\n",
    "\n",
    "# Generate the classification report\n",
    "target_names = le.classes_  # Replace with your actual class names\n",
    "\n",
    "print('Validation Performance:\\n')\n",
    "print(classification_report(y_val_some, y_pred_dlv, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "Test Performance:\n",
      "\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    battery issue       0.83      1.00      0.91         5\n",
      "             bmis       0.67      1.00      0.80         2\n",
      "      cable issue       0.72      0.76      0.74        17\n",
      "data access issue       0.63      0.80      0.71        15\n",
      "decision accuracy       0.14      0.20      0.17         5\n",
      "    display issue       0.50      0.50      0.50         2\n",
      "        fan issue       0.71      0.71      0.71         7\n",
      "          freezes       0.80      0.67      0.73         6\n",
      "   hardware issue       0.20      0.17      0.18         6\n",
      "       no details       0.86      0.92      0.89        13\n",
      "      power issue       0.67      0.50      0.57         4\n",
      "        shuts off       0.60      0.75      0.67         4\n",
      "   software issue       0.33      0.25      0.29         4\n",
      "temp sensor error       1.00      0.50      0.67         2\n",
      "    testing issue       0.67      0.67      0.67         3\n",
      "    update issues       0.97      0.88      0.92        41\n",
      "         vin scan       0.67      0.75      0.71         8\n",
      "      wifi issues       1.00      0.79      0.88        14\n",
      "\n",
      "         accuracy                           0.75       158\n",
      "        macro avg       0.67      0.66      0.65       158\n",
      "     weighted avg       0.76      0.75      0.75       158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have trained and evaluated your model on the test dataset\n",
    "y_proba_dlt = loaded_model.predict(X_test_some)\n",
    "y_pred_dlt = np.argmax(y_proba_dlt, axis=1)\n",
    "\n",
    "\n",
    "##Second Best DL Model\n",
    "y_proba_dlt2 = loaded_model2.predict(X_test_some)\n",
    "y_pred_dlt2 = np.argmax(y_proba_dlt2, axis=1)\n",
    "\n",
    "# Generate the classification report\n",
    "target_names = le.classes_  # Replace with your actual class names\n",
    "print('Test Performance:\\n')\n",
    "print(classification_report(y_test_some, y_pred_dlt, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17, 15, 15,  9, 15, 15, 15,  0, 15,  9, 15,  7, 15, 15, 16, 17,  7,\n",
       "       15,  8, 17, 15,  1,  9,  3, 15, 15,  4,  2,  2, 15,  2, 17,  3, 15,\n",
       "       17,  8,  5, 12,  7, 11, 15,  6, 15,  0, 15,  6,  3,  2,  3, 12,  2,\n",
       "        9, 15,  4,  9, 17,  9,  2,  7, 15, 17,  3,  6,  2, 15,  2,  3, 15,\n",
       "       15,  7, 15,  3,  8, 16, 10, 10,  6,  8, 15,  9, 16, 15,  2,  3, 15,\n",
       "        9,  7,  9,  1, 16, 15, 15,  3, 17,  2, 12, 10, 12, 15, 15,  5, 14,\n",
       "       15,  2, 17,  4, 15,  9,  4, 15,  8,  9, 15, 16,  4,  6,  8, 15, 16,\n",
       "        3,  6,  2, 15, 11, 13,  3, 13, 15,  0, 10,  2,  2,  0, 16,  0, 15,\n",
       "        3, 17, 17,  2,  2, 15,  3, 15,  3, 11, 17, 14,  6, 17,  3, 11, 16,\n",
       "       17,  9, 14,  2,  9])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_some"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
       "              feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softmax&#x27;, predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;mlogloss&#x27;,\n",
       "              feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softmax&#x27;, predictor=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='mlogloss',\n",
       "              feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, objective='multi:softmax', predictor=None, ...)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "X_meta = np.concatenate([y_proba_dlv,y_proba_dlv2], axis=1)\n",
    "\n",
    "# Train a meta-learner model on the predicted probabilities\n",
    "# Here we use XGBoost as the meta-learner\n",
    "meta_learner = XGBClassifier(random_state=42,eval_metric='mlogloss',objective = 'multi:softmax')\n",
    "meta_learner.fit(X_meta, y_val_some)  # Assuming y_test_all and y_test_some are the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 710us/step\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    battery issue       1.00      1.00      1.00         5\n",
      "             bmis       1.00      1.00      1.00         2\n",
      "      cable issue       1.00      1.00      1.00        17\n",
      "data access issue       1.00      1.00      1.00        14\n",
      "decision accuracy       1.00      1.00      1.00         5\n",
      "    display issue       1.00      1.00      1.00         3\n",
      "        fan issue       1.00      1.00      1.00         7\n",
      "          freezes       1.00      1.00      1.00         5\n",
      "   hardware issue       1.00      1.00      1.00         6\n",
      "       no details       1.00      1.00      1.00        12\n",
      "      power issue       1.00      1.00      1.00         4\n",
      "        shuts off       1.00      0.75      0.86         4\n",
      "   software issue       1.00      1.00      1.00         5\n",
      "temp sensor error       1.00      1.00      1.00         3\n",
      "    testing issue       1.00      1.00      1.00         4\n",
      "    update issues       0.98      1.00      0.99        41\n",
      "         vin scan       1.00      1.00      1.00         7\n",
      "      wifi issues       1.00      1.00      1.00        13\n",
      "\n",
      "         accuracy                           0.99       157\n",
      "        macro avg       1.00      0.99      0.99       157\n",
      "     weighted avg       0.99      0.99      0.99       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_proba_dlv = loaded_model.predict(X_val_some)\n",
    "X_meta_val = np.concatenate([y_proba_dlv, y_proba_dlv2], axis=1)\n",
    "y_pred_meta = meta_learner.predict(X_meta_val)\n",
    "\n",
    "print(classification_report(y_val_some, y_pred_meta,target_names = le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_meta_test = np.concatenate([y_proba_dlt, y_proba_dlt2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    battery issue       0.83      1.00      0.91         5\n",
      "             bmis       1.00      0.50      0.67         2\n",
      "      cable issue       0.68      0.76      0.72        17\n",
      "data access issue       0.67      0.67      0.67        15\n",
      "decision accuracy       0.50      0.20      0.29         5\n",
      "    display issue       0.50      0.50      0.50         2\n",
      "        fan issue       0.60      0.86      0.71         7\n",
      "          freezes       0.67      0.67      0.67         6\n",
      "   hardware issue       0.29      0.33      0.31         6\n",
      "       no details       1.00      0.85      0.92        13\n",
      "      power issue       0.00      0.00      0.00         4\n",
      "        shuts off       0.33      0.50      0.40         4\n",
      "   software issue       0.00      0.00      0.00         4\n",
      "temp sensor error       1.00      0.50      0.67         2\n",
      "    testing issue       0.33      0.33      0.33         3\n",
      "    update issues       0.91      0.95      0.93        41\n",
      "         vin scan       0.64      0.88      0.74         8\n",
      "      wifi issues       1.00      0.64      0.78        14\n",
      "\n",
      "         accuracy                           0.72       158\n",
      "        macro avg       0.61      0.56      0.57       158\n",
      "     weighted avg       0.73      0.72      0.71       158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_meta = meta_learner.predict(X_meta_test)\n",
    "\n",
    "print(classification_report(y_test_some, y_pred_meta,target_names = le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Meta Learner Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-16 12:52:55,442] A new study created in memory with name: no-name-fd03715a-2f7c-4864-9791-1a40aeb797f9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "239bed6c5d0c4ab6a14e0a59165ab379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 5ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "[I 2023-08-16 12:52:58,040] Trial 0 finished with value: 0.6430878006455072 and parameters: {'max_depth': 10, 'learning_rate': 0.028894143326076368, 'n_estimators': 60, 'subsample': 0.3336614741312672, 'colsample_bytree': 0.6548827083255392, 'reg_alpha': 0.1530066144102149, 'reg_lambda': 0.8762655880515675}. Best is trial 0 with value: 0.6430878006455072.\n",
      "5/5 [==============================] - 0s 832us/step\n",
      "[I 2023-08-16 12:52:58,071] Trial 6 pruned. Trial was pruned at iteration 44.\n",
      "[I 2023-08-16 12:52:58,088] Trial 1 pruned. Trial was pruned at iteration 49.\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:52:58,818] Trial 10 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 700us/step\n",
      "[I 2023-08-16 12:52:59,792] Trial 3 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 722us/step\n",
      "[I 2023-08-16 12:52:59,876] Trial 2 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 895us/step\n",
      "[I 2023-08-16 12:53:00,981] Trial 12 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 943us/step\n",
      "[I 2023-08-16 12:53:01,134] Trial 9 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:53:01,185] Trial 13 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 867us/step\n",
      "[I 2023-08-16 12:53:01,903] Trial 7 finished with value: 0.6997729722254518 and parameters: {'max_depth': 5, 'learning_rate': 0.08906259567263386, 'n_estimators': 130, 'subsample': 0.5574111048264637, 'colsample_bytree': 0.42814431391769764, 'reg_alpha': 0.9615528617404823, 'reg_lambda': 0.8706508015360028}. Best is trial 7 with value: 0.6997729722254518.\n",
      "5/5 [==============================] - 0s 887us/step\n",
      "[I 2023-08-16 12:53:02,170] Trial 14 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 637us/step\n",
      "[I 2023-08-16 12:53:02,961] Trial 4 finished with value: 0.7180449014905719 and parameters: {'max_depth': 7, 'learning_rate': 0.037914583026431935, 'n_estimators': 146, 'subsample': 0.5736373943198284, 'colsample_bytree': 0.8749771610457713, 'reg_alpha': 0.45261287773891445, 'reg_lambda': 0.8360368643167558}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 967us/step\n",
      "[I 2023-08-16 12:53:03,148] Trial 16 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 969us/step\n",
      "[I 2023-08-16 12:53:05,252] Trial 5 finished with value: 0.7076122979779308 and parameters: {'max_depth': 6, 'learning_rate': 0.03416299157337853, 'n_estimators': 153, 'subsample': 0.9423646382014448, 'colsample_bytree': 0.7833602746417142, 'reg_alpha': 0.5468354273421279, 'reg_lambda': 0.9928143316008824}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:53:05,311] Trial 15 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 783us/step\n",
      "[I 2023-08-16 12:53:10,808] Trial 19 finished with value: 0.6063360399549805 and parameters: {'max_depth': 5, 'learning_rate': 0.0994020269168848, 'n_estimators': 231, 'subsample': 0.2239116272377376, 'colsample_bytree': 0.21428634963521315, 'reg_alpha': 0.6554223803107473, 'reg_lambda': 0.9666438667552812}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 966us/step\n",
      "[I 2023-08-16 12:53:11,504] Trial 11 finished with value: 0.6864171351901612 and parameters: {'max_depth': 8, 'learning_rate': 0.05965670656139353, 'n_estimators': 280, 'subsample': 0.5280959059946517, 'colsample_bytree': 0.29129141615076987, 'reg_alpha': 0.9883709537520026, 'reg_lambda': 0.3465363301803961}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 705us/step\n",
      "[I 2023-08-16 12:53:12,502] Trial 23 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 663us/step\n",
      "[I 2023-08-16 12:53:12,560] Trial 17 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 744us/step\n",
      "[I 2023-08-16 12:53:13,097] Trial 24 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 628us/step\n",
      "[I 2023-08-16 12:53:13,705] Trial 21 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 817us/step\n",
      "[I 2023-08-16 12:53:13,795] Trial 25 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 781us/step\n",
      "[I 2023-08-16 12:53:13,842] Trial 20 pruned. Trial was pruned at iteration 225.\n",
      "[I 2023-08-16 12:53:13,854] Trial 26 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:53:13,988] Trial 22 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 744us/step\n",
      "[I 2023-08-16 12:53:14,558] Trial 27 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 746us/step\n",
      "[I 2023-08-16 12:53:14,910] Trial 28 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 690us/step\n",
      "[I 2023-08-16 12:53:14,977] Trial 29 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 834us/step\n",
      "[I 2023-08-16 12:53:15,098] Trial 31 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:53:15,209] Trial 32 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 731us/step\n",
      "[I 2023-08-16 12:53:15,502] Trial 8 finished with value: 0.7053035220307551 and parameters: {'max_depth': 7, 'learning_rate': 0.09697463397316322, 'n_estimators': 429, 'subsample': 0.5569790351299015, 'colsample_bytree': 0.2244710559291283, 'reg_alpha': 0.6270226605409964, 'reg_lambda': 0.7241872237046261}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 719us/step\n",
      "[I 2023-08-16 12:53:15,869] Trial 33 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 779us/step\n",
      "[I 2023-08-16 12:53:16,328] Trial 34 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 628us/step\n",
      "[I 2023-08-16 12:53:16,411] Trial 35 pruned. Trial was pruned at iteration 25.\n",
      "[I 2023-08-16 12:53:16,444] Trial 36 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:53:16,581] Trial 37 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 690us/step\n",
      "[I 2023-08-16 12:53:16,850] Trial 38 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 958us/step\n",
      "[I 2023-08-16 12:53:17,301] Trial 39 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:53:17,506] Trial 30 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 937us/step\n",
      "[I 2023-08-16 12:53:17,714] Trial 18 finished with value: 0.6813728444964485 and parameters: {'max_depth': 10, 'learning_rate': 0.09569509819132735, 'n_estimators': 491, 'subsample': 0.20511380294041454, 'colsample_bytree': 0.33377210455161527, 'reg_alpha': 0.6492741741008788, 'reg_lambda': 0.9754201410297779}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 673us/step\n",
      "[I 2023-08-16 12:53:17,818] Trial 40 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:53:20,564] Trial 41 pruned. Trial was pruned at iteration 75.\n",
      "[I 2023-08-16 12:53:20,586] Trial 42 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 978us/step\n",
      "5/5 [==============================] - 0s 783us/step\n",
      "[I 2023-08-16 12:53:20,797] Trial 45 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 671us/step\n",
      "[I 2023-08-16 12:53:21,120] Trial 47 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:53:21,577] Trial 43 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 806us/step\n",
      "[I 2023-08-16 12:53:21,641] Trial 48 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 922us/step\n",
      "[I 2023-08-16 12:53:21,829] Trial 44 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 901us/step\n",
      "[I 2023-08-16 12:53:22,080] Trial 51 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 808us/step\n",
      "[I 2023-08-16 12:53:22,326] Trial 46 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 648us/step\n",
      "[I 2023-08-16 12:53:22,987] Trial 54 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 744us/step\n",
      "[I 2023-08-16 12:53:23,105] Trial 55 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 774us/step\n",
      "[I 2023-08-16 12:53:26,175] Trial 56 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 627us/step\n",
      "[I 2023-08-16 12:53:26,753] Trial 57 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 791us/step\n",
      "[I 2023-08-16 12:53:28,350] Trial 58 finished with value: 0.6267109325624788 and parameters: {'max_depth': 10, 'learning_rate': 0.0960227680764555, 'n_estimators': 140, 'subsample': 0.27542689158315625, 'colsample_bytree': 0.2697038634580245, 'reg_alpha': 0.6802927541347861, 'reg_lambda': 0.9531255708408459}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 791us/step\n",
      "[I 2023-08-16 12:53:29,886] Trial 61 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 812us/step\n",
      "[I 2023-08-16 12:53:30,154] Trial 52 finished with value: 0.7021201179456429 and parameters: {'max_depth': 9, 'learning_rate': 0.0594634825178986, 'n_estimators': 179, 'subsample': 0.6269474482813436, 'colsample_bytree': 0.25113560532496376, 'reg_alpha': 0.9656300420375624, 'reg_lambda': 0.6589445651456545}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 592us/step\n",
      "[I 2023-08-16 12:53:30,359] Trial 49 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 816us/step\n",
      "[I 2023-08-16 12:53:31,399] Trial 62 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 906us/step\n",
      "[I 2023-08-16 12:53:31,796] Trial 59 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 660us/step\n",
      "[I 2023-08-16 12:53:31,864] Trial 53 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 622us/step\n",
      "[I 2023-08-16 12:53:32,166] Trial 50 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 841us/step\n",
      "[I 2023-08-16 12:53:34,187] Trial 60 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 660us/step\n",
      "[I 2023-08-16 12:53:35,872] Trial 70 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 683us/step\n",
      "[I 2023-08-16 12:53:36,416] Trial 68 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 813us/step\n",
      "[I 2023-08-16 12:53:38,826] Trial 64 finished with value: 0.6585537693038649 and parameters: {'max_depth': 5, 'learning_rate': 0.034608759554718566, 'n_estimators': 174, 'subsample': 0.5277069798648986, 'colsample_bytree': 0.2226123119254883, 'reg_alpha': 0.8123751814541647, 'reg_lambda': 0.7379621932697422}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 784us/step\n",
      "[I 2023-08-16 12:53:39,693] Trial 65 finished with value: 0.6519577945246915 and parameters: {'max_depth': 5, 'learning_rate': 0.03196454603402248, 'n_estimators': 175, 'subsample': 0.5249621188743323, 'colsample_bytree': 0.20450599538761022, 'reg_alpha': 0.8179358637735701, 'reg_lambda': 0.7428363191593899}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 678us/step\n",
      "[I 2023-08-16 12:53:41,521] Trial 66 finished with value: 0.6354797523450139 and parameters: {'max_depth': 5, 'learning_rate': 0.03350373550192857, 'n_estimators': 176, 'subsample': 0.5098912209323461, 'colsample_bytree': 0.2083405036479396, 'reg_alpha': 0.9585818916005431, 'reg_lambda': 0.7348667075473626}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 699us/step\n",
      "[I 2023-08-16 12:53:42,493] Trial 74 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 706us/step\n",
      "[I 2023-08-16 12:53:44,247] Trial 67 finished with value: 0.6831875788539836 and parameters: {'max_depth': 5, 'learning_rate': 0.03668545884627328, 'n_estimators': 157, 'subsample': 0.8449182895341512, 'colsample_bytree': 0.2257232741841582, 'reg_alpha': 0.4725335885633722, 'reg_lambda': 0.7356407020063891}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:53:45,095] Trial 76 finished with value: 0.2399349928330608 and parameters: {'max_depth': 6, 'learning_rate': 0.03730096269364906, 'n_estimators': 51, 'subsample': 0.20178525364040062, 'colsample_bytree': 0.24304195199890555, 'reg_alpha': 0.9517478332662093, 'reg_lambda': 0.8748935931227697}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 652us/step\n",
      "[I 2023-08-16 12:53:46,139] Trial 77 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[I 2023-08-16 12:53:46,451] Trial 71 finished with value: 0.6574223015207877 and parameters: {'max_depth': 6, 'learning_rate': 0.036891486111486446, 'n_estimators': 170, 'subsample': 0.43919555439776337, 'colsample_bytree': 0.25138358605757716, 'reg_alpha': 0.5936430723780799, 'reg_lambda': 0.8589707429910242}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 711us/step\n",
      "[I 2023-08-16 12:53:47,301] Trial 78 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:53:47,442] Trial 63 finished with value: 0.6608046038310368 and parameters: {'max_depth': 5, 'learning_rate': 0.0811320862154522, 'n_estimators': 497, 'subsample': 0.20116269200010875, 'colsample_bytree': 0.37403369524653873, 'reg_alpha': 0.6264193274045387, 'reg_lambda': 0.9468621315316559}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 765us/step\n",
      "[I 2023-08-16 12:53:48,396] Trial 80 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 937us/step\n",
      "[I 2023-08-16 12:53:49,837] Trial 82 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 883us/step\n",
      "[I 2023-08-16 12:53:50,293] Trial 72 finished with value: 0.6309948665512136 and parameters: {'max_depth': 6, 'learning_rate': 0.037469027185938475, 'n_estimators': 216, 'subsample': 0.44309755439944887, 'colsample_bytree': 0.23649077527841889, 'reg_alpha': 0.952365134763288, 'reg_lambda': 0.8814162886695879}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 889us/step\n",
      "[I 2023-08-16 12:53:51,147] Trial 69 finished with value: 0.6136184479082192 and parameters: {'max_depth': 5, 'learning_rate': 0.09796264962760468, 'n_estimators': 500, 'subsample': 0.2045259451807258, 'colsample_bytree': 0.2116665774509991, 'reg_alpha': 0.9500965066869729, 'reg_lambda': 0.876955614505668}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 702us/step\n",
      "[I 2023-08-16 12:53:51,867] Trial 84 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 753us/step\n",
      "[I 2023-08-16 12:53:52,466] Trial 85 pruned. Trial was pruned at iteration 25.\n",
      "[I 2023-08-16 12:53:52,492] Trial 79 finished with value: 0.6465130825257145 and parameters: {'max_depth': 1, 'learning_rate': 0.04522153191361898, 'n_estimators': 152, 'subsample': 0.44433791930272254, 'colsample_bytree': 0.23534096796483792, 'reg_alpha': 0.5748583265699094, 'reg_lambda': 0.8203505000259037}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:53:53,416] Trial 81 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 623us/step\n",
      "[I 2023-08-16 12:53:53,811] Trial 83 pruned. Trial was pruned at iteration 75.\n",
      "[I 2023-08-16 12:53:53,841] Trial 88 pruned. Trial was pruned at iteration 25.\n",
      "1/5 [=====>........................] - ETA: 0s[I 2023-08-16 12:53:53,880] Trial 89 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 768us/step\n",
      "[I 2023-08-16 12:53:55,242] Trial 86 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[I 2023-08-16 12:53:55,376] Trial 93 pruned. Trial was pruned at iteration 25.\n",
      "[I 2023-08-16 12:53:55,389] Trial 91 pruned. Trial was pruned at iteration 25.\n",
      "[I 2023-08-16 12:53:55,392] Trial 87 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 985us/step\n",
      "5/5 [==============================] - 0s 966us/step\n",
      "[I 2023-08-16 12:53:56,639] Trial 94 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 628us/step\n",
      "[I 2023-08-16 12:53:56,754] Trial 95 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:53:56,875] Trial 97 pruned. Trial was pruned at iteration 25.\n",
      "[I 2023-08-16 12:53:56,880] Trial 96 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 963us/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:53:57,882] Trial 92 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 990us/step\n",
      "[I 2023-08-16 12:54:00,631] Trial 100 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 697us/step\n",
      "[I 2023-08-16 12:54:00,913] Trial 101 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 811us/step\n",
      "[I 2023-08-16 12:54:02,283] Trial 104 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 624us/step\n",
      "[I 2023-08-16 12:54:04,141] Trial 102 finished with value: 0.6447525513252795 and parameters: {'max_depth': 6, 'learning_rate': 0.03532721428654603, 'n_estimators': 127, 'subsample': 0.4993360715111768, 'colsample_bytree': 0.22360922654782722, 'reg_alpha': 0.8945135970237764, 'reg_lambda': 0.7690424398213663}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 768us/step\n",
      "[I 2023-08-16 12:54:05,148] Trial 73 finished with value: 0.6690618289664699 and parameters: {'max_depth': 6, 'learning_rate': 0.02961236814153491, 'n_estimators': 490, 'subsample': 0.4297571038823329, 'colsample_bytree': 0.2420057979198575, 'reg_alpha': 0.648921504316201, 'reg_lambda': 0.8696144828020214}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 726us/step\n",
      "[I 2023-08-16 12:54:06,779] Trial 105 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 726us/step\n",
      "[I 2023-08-16 12:54:07,777] Trial 75 finished with value: 0.6679366531577497 and parameters: {'max_depth': 6, 'learning_rate': 0.02918991699422663, 'n_estimators': 499, 'subsample': 0.43674339400797046, 'colsample_bytree': 0.2457701009892498, 'reg_alpha': 0.6324947243963517, 'reg_lambda': 0.873881908119746}. Best is trial 4 with value: 0.7180449014905719.\n",
      "[I 2023-08-16 12:54:07,806] Trial 103 finished with value: 0.6619688453585271 and parameters: {'max_depth': 6, 'learning_rate': 0.035517751828890914, 'n_estimators': 127, 'subsample': 0.536687973335266, 'colsample_bytree': 0.25924201798111307, 'reg_alpha': 0.876556068808249, 'reg_lambda': 0.8505349976828583}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 800us/step\n",
      "[I 2023-08-16 12:54:08,068] Trial 98 pruned. Trial was pruned at iteration 225.\n",
      "[I 2023-08-16 12:54:08,112] Trial 99 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:54:08,826] Trial 106 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 661us/step\n",
      "[I 2023-08-16 12:54:10,837] Trial 90 finished with value: 0.6691420585682825 and parameters: {'max_depth': 4, 'learning_rate': 0.03974008697756186, 'n_estimators': 478, 'subsample': 0.24129430864438314, 'colsample_bytree': 0.2731480008086189, 'reg_alpha': 0.6609171857160674, 'reg_lambda': 0.9306704010467318}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 708us/step\n",
      "[I 2023-08-16 12:54:13,972] Trial 113 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 709us/step\n",
      "[I 2023-08-16 12:54:14,899] Trial 110 finished with value: 0.6295496813067792 and parameters: {'max_depth': 6, 'learning_rate': 0.031473549599206826, 'n_estimators': 110, 'subsample': 0.4589083781245817, 'colsample_bytree': 0.26216349520299387, 'reg_alpha': 0.6045343101554667, 'reg_lambda': 0.8431766541087008}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 621us/step\n",
      "[I 2023-08-16 12:54:16,076] Trial 114 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 745us/step\n",
      "[I 2023-08-16 12:54:17,639] Trial 115 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 787us/step\n",
      "[I 2023-08-16 12:54:19,219] Trial 108 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 822us/step\n",
      "[I 2023-08-16 12:54:20,439] Trial 111 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:54:20,615] Trial 119 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 790us/step\n",
      "[I 2023-08-16 12:54:21,553] Trial 120 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 896us/step\n",
      "[I 2023-08-16 12:54:21,751] Trial 112 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 800us/step\n",
      "[I 2023-08-16 12:54:22,941] Trial 122 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 864us/step\n",
      "[I 2023-08-16 12:54:23,445] Trial 107 finished with value: 0.6757157129089977 and parameters: {'max_depth': 6, 'learning_rate': 0.09260224908003856, 'n_estimators': 492, 'subsample': 0.23886016103922503, 'colsample_bytree': 0.25805920506782287, 'reg_alpha': 0.541725158407288, 'reg_lambda': 0.9986461298481194}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 699us/step\n",
      "[I 2023-08-16 12:54:29,510] Trial 109 finished with value: 0.6692106323358549 and parameters: {'max_depth': 6, 'learning_rate': 0.031334254439972654, 'n_estimators': 433, 'subsample': 0.3974475692513769, 'colsample_bytree': 0.20024706847097903, 'reg_alpha': 0.5983753702430185, 'reg_lambda': 0.8507205377259422}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:54:30,206] Trial 118 finished with value: 0.5893979644461207 and parameters: {'max_depth': 6, 'learning_rate': 0.03807283211615258, 'n_estimators': 316, 'subsample': 0.22641711690137345, 'colsample_bytree': 0.20105751249027512, 'reg_alpha': 0.5446285976627744, 'reg_lambda': 0.8695152861712082}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 710us/step\n",
      "[I 2023-08-16 12:54:30,613] Trial 116 finished with value: 0.6618795752395469 and parameters: {'max_depth': 2, 'learning_rate': 0.03845591587706075, 'n_estimators': 432, 'subsample': 0.22651521357260695, 'colsample_bytree': 0.32226661892689407, 'reg_alpha': 0.5469116179415121, 'reg_lambda': 0.9995848644885067}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 695us/step\n",
      "[I 2023-08-16 12:54:33,234] Trial 117 finished with value: 0.6207353020290582 and parameters: {'max_depth': 8, 'learning_rate': 0.026575793570937763, 'n_estimators': 433, 'subsample': 0.2221772678964971, 'colsample_bytree': 0.3283499061410947, 'reg_alpha': 0.5526064348598531, 'reg_lambda': 0.9286460998923655}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 726us/step\n",
      "[I 2023-08-16 12:54:40,941] Trial 121 finished with value: 0.5935259617813062 and parameters: {'max_depth': 7, 'learning_rate': 0.03816979380723941, 'n_estimators': 469, 'subsample': 0.2309783408067974, 'colsample_bytree': 0.2424531895135527, 'reg_alpha': 0.9311082242451675, 'reg_lambda': 0.8672811564418595}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 844us/step\n",
      "[I 2023-08-16 12:54:42,295] Trial 127 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:54:44,552] Trial 125 finished with value: 0.6433927256849914 and parameters: {'max_depth': 8, 'learning_rate': 0.09724486779955858, 'n_estimators': 473, 'subsample': 0.2351461331947941, 'colsample_bytree': 0.24283055447819557, 'reg_alpha': 0.5426240226768317, 'reg_lambda': 0.9574788163170179}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[I 2023-08-16 12:54:44,723] Trial 123 finished with value: 0.6566707120132289 and parameters: {'max_depth': 8, 'learning_rate': 0.038079078676714145, 'n_estimators': 469, 'subsample': 0.24350767414286587, 'colsample_bytree': 0.24415523185048288, 'reg_alpha': 0.5463041433400535, 'reg_lambda': 0.9562550830781159}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:54:45,419] Trial 124 finished with value: 0.640705731948318 and parameters: {'max_depth': 7, 'learning_rate': 0.04212370292852431, 'n_estimators': 474, 'subsample': 0.22158435999333675, 'colsample_bytree': 0.24182336218223266, 'reg_alpha': 0.5427635222295458, 'reg_lambda': 0.9974517095862877}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 778us/step\n",
      "[I 2023-08-16 12:54:47,118] Trial 129 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 683us/step\n",
      "[I 2023-08-16 12:54:48,144] Trial 126 finished with value: 0.646555183405644 and parameters: {'max_depth': 8, 'learning_rate': 0.09666343501790119, 'n_estimators': 407, 'subsample': 0.24613954468948324, 'colsample_bytree': 0.23902752240859967, 'reg_alpha': 0.5539447870706768, 'reg_lambda': 0.9621755531666739}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 758us/step\n",
      "[I 2023-08-16 12:54:48,507] Trial 134 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 842us/step\n",
      "[I 2023-08-16 12:54:49,576] Trial 137 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 840us/step\n",
      "[I 2023-08-16 12:54:50,342] Trial 130 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 687us/step\n",
      "[I 2023-08-16 12:54:53,153] Trial 133 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 863us/step\n",
      "[I 2023-08-16 12:54:53,278] Trial 128 finished with value: 0.6371588699521175 and parameters: {'max_depth': 8, 'learning_rate': 0.02822728468589263, 'n_estimators': 473, 'subsample': 0.2622398398729691, 'colsample_bytree': 0.2409285994615794, 'reg_alpha': 0.6458310958627953, 'reg_lambda': 0.9469307874393097}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 687us/step\n",
      "[I 2023-08-16 12:54:55,260] Trial 132 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 796us/step\n",
      "[I 2023-08-16 12:54:57,467] Trial 140 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 965us/step\n",
      "[I 2023-08-16 12:54:58,579] Trial 143 pruned. Trial was pruned at iteration 25.\n",
      "[I 2023-08-16 12:54:58,607] Trial 142 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 7ms/step\n",
      "[I 2023-08-16 12:54:59,799] Trial 145 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 839us/step\n",
      "[I 2023-08-16 12:54:59,918] Trial 144 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 653us/step\n",
      "[I 2023-08-16 12:55:00,484] Trial 138 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 680us/step\n",
      "[I 2023-08-16 12:55:01,175] Trial 146 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:55:01,335] Trial 147 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 827us/step\n",
      "[I 2023-08-16 12:55:02,378] Trial 131 finished with value: 0.6602597155221444 and parameters: {'max_depth': 10, 'learning_rate': 0.040884870840954, 'n_estimators': 500, 'subsample': 0.2629551370260279, 'colsample_bytree': 0.2453609154697494, 'reg_alpha': 0.6501629191457848, 'reg_lambda': 0.9741221275553226}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 735us/step\n",
      "[I 2023-08-16 12:55:02,994] Trial 139 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 688us/step\n",
      "[I 2023-08-16 12:55:04,305] Trial 141 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 950us/step\n",
      "[I 2023-08-16 12:55:06,552] Trial 148 finished with value: 0.6057595709437424 and parameters: {'max_depth': 2, 'learning_rate': 0.0335893864451052, 'n_estimators': 149, 'subsample': 0.2841278589778011, 'colsample_bytree': 0.32046343232413677, 'reg_alpha': 0.5205498475790316, 'reg_lambda': 0.9791661046878369}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 966us/step\n",
      "[I 2023-08-16 12:55:07,894] Trial 154 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 835us/step\n",
      "[I 2023-08-16 12:55:08,177] Trial 135 finished with value: 0.6701474592220489 and parameters: {'max_depth': 10, 'learning_rate': 0.0287524462357093, 'n_estimators': 496, 'subsample': 0.2970229002096648, 'colsample_bytree': 0.27771091859563674, 'reg_alpha': 0.5949450787683139, 'reg_lambda': 0.9133772183609429}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 759us/step\n",
      "[I 2023-08-16 12:55:09,317] Trial 136 finished with value: 0.6653401225269675 and parameters: {'max_depth': 10, 'learning_rate': 0.028733406453567825, 'n_estimators': 496, 'subsample': 0.30240088099742335, 'colsample_bytree': 0.27700102854182634, 'reg_alpha': 0.6189529850971216, 'reg_lambda': 0.9062933438372922}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 818us/step\n",
      "[I 2023-08-16 12:55:10,074] Trial 156 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 862us/step\n",
      "[I 2023-08-16 12:55:10,465] Trial 149 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 840us/step\n",
      "[I 2023-08-16 12:55:10,731] Trial 150 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 737us/step\n",
      "[I 2023-08-16 12:55:11,662] Trial 159 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 894us/step\n",
      "[I 2023-08-16 12:55:12,141] Trial 151 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 819us/step\n",
      "[I 2023-08-16 12:55:12,559] Trial 152 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 904us/step\n",
      "[I 2023-08-16 12:55:13,433] Trial 153 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 669us/step\n",
      "[I 2023-08-16 12:55:16,942] Trial 164 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 663us/step\n",
      "[I 2023-08-16 12:55:17,712] Trial 158 finished with value: 0.6090478792659223 and parameters: {'max_depth': 10, 'learning_rate': 0.023029402758423165, 'n_estimators': 183, 'subsample': 0.3104913377770556, 'colsample_bytree': 0.26168313361774664, 'reg_alpha': 0.6126260826265202, 'reg_lambda': 0.9087887789953754}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 791us/step\n",
      "[I 2023-08-16 12:55:18,074] Trial 165 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 838us/step\n",
      "[I 2023-08-16 12:55:18,937] Trial 157 finished with value: 0.5654714829479713 and parameters: {'max_depth': 10, 'learning_rate': 0.02173702252888691, 'n_estimators': 236, 'subsample': 0.2898996094392996, 'colsample_bytree': 0.2976233026238521, 'reg_alpha': 0.8376584059951604, 'reg_lambda': 0.9198845419353354}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 844us/step\n",
      "[I 2023-08-16 12:55:19,441] Trial 155 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 754us/step\n",
      "[I 2023-08-16 12:55:20,041] Trial 167 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 823us/step\n",
      "[I 2023-08-16 12:55:20,599] Trial 160 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:55:20,858] Trial 170 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 669us/step\n",
      "[I 2023-08-16 12:55:20,923] Trial 169 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 695us/step\n",
      "[I 2023-08-16 12:55:21,254] Trial 163 finished with value: 0.6174529396471846 and parameters: {'max_depth': 10, 'learning_rate': 0.027633199774844144, 'n_estimators': 202, 'subsample': 0.3145463786882964, 'colsample_bytree': 0.2570114429414325, 'reg_alpha': 0.5727377005617453, 'reg_lambda': 0.651602336695893}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 782us/step\n",
      "[I 2023-08-16 12:55:21,829] Trial 162 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 855us/step\n",
      "[I 2023-08-16 12:55:22,280] Trial 168 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 862us/step\n",
      "[I 2023-08-16 12:55:24,013] Trial 176 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 653us/step\n",
      "[I 2023-08-16 12:55:27,474] Trial 166 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 744us/step\n",
      "[I 2023-08-16 12:55:30,220] Trial 172 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 951us/step\n",
      "[I 2023-08-16 12:55:31,262] Trial 174 finished with value: 0.5972330513001949 and parameters: {'max_depth': 7, 'learning_rate': 0.030632888513991822, 'n_estimators': 275, 'subsample': 0.20965854418882957, 'colsample_bytree': 0.2908668606589224, 'reg_alpha': 0.5664942194413698, 'reg_lambda': 0.7797137334525235}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 717us/step\n",
      "[I 2023-08-16 12:55:32,257] Trial 161 finished with value: 0.6614644375269342 and parameters: {'max_depth': 10, 'learning_rate': 0.027230645872042453, 'n_estimators': 489, 'subsample': 0.3272884362094226, 'colsample_bytree': 0.2562397480823517, 'reg_alpha': 0.5700673632751326, 'reg_lambda': 0.8675070656737323}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 703us/step\n",
      "[I 2023-08-16 12:55:34,371] Trial 180 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 725us/step\n",
      "[I 2023-08-16 12:55:35,124] Trial 179 finished with value: 0.4624041081608185 and parameters: {'max_depth': 5, 'learning_rate': 0.03202570767879762, 'n_estimators': 138, 'subsample': 0.20491120901456367, 'colsample_bytree': 0.37150491900780364, 'reg_alpha': 0.9654245803794628, 'reg_lambda': 0.9509589666236257}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 843us/step\n",
      "[I 2023-08-16 12:55:35,605] Trial 173 finished with value: 0.6021513043284243 and parameters: {'max_depth': 7, 'learning_rate': 0.042708483720519275, 'n_estimators': 444, 'subsample': 0.20910673237990232, 'colsample_bytree': 0.29370079125048143, 'reg_alpha': 0.9536675475603881, 'reg_lambda': 0.7681303798979151}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 752us/step\n",
      "[I 2023-08-16 12:55:36,060] Trial 171 finished with value: 0.6316440959804753 and parameters: {'max_depth': 3, 'learning_rate': 0.0763763389137474, 'n_estimators': 478, 'subsample': 0.2166798815757238, 'colsample_bytree': 0.29157638296318333, 'reg_alpha': 0.9562207925560363, 'reg_lambda': 0.769492634584186}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 701us/step\n",
      "[I 2023-08-16 12:55:36,234] Trial 181 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:55:36,605] Trial 182 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 699us/step\n",
      "[I 2023-08-16 12:55:36,784] Trial 183 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 701us/step\n",
      "[I 2023-08-16 12:55:37,261] Trial 184 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 712us/step\n",
      "[I 2023-08-16 12:55:37,624] Trial 185 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:55:37,836] Trial 188 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 847us/step\n",
      "[I 2023-08-16 12:55:37,914] Trial 187 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 784us/step\n",
      "[I 2023-08-16 12:55:38,070] Trial 186 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:55:38,996] Trial 192 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 645us/step\n",
      "[I 2023-08-16 12:55:39,154] Trial 193 pruned. Trial was pruned at iteration 25.\n",
      "[I 2023-08-16 12:55:39,226] Trial 175 finished with value: 0.6195527472439764 and parameters: {'max_depth': 3, 'learning_rate': 0.043111326343904036, 'n_estimators': 500, 'subsample': 0.2023212386672767, 'colsample_bytree': 0.2202757750191192, 'reg_alpha': 0.43103244184329975, 'reg_lambda': 0.7736951383786361}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 985us/step\n",
      "[I 2023-08-16 12:55:40,236] Trial 194 pruned. Trial was pruned at iteration 25.\n",
      "[I 2023-08-16 12:55:40,293] Trial 196 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 840us/step\n",
      "[I 2023-08-16 12:55:40,402] Trial 195 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 821us/step\n",
      "[I 2023-08-16 12:55:40,507] Trial 191 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 877us/step\n",
      "[I 2023-08-16 12:55:41,459] Trial 197 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 853us/step\n",
      "[I 2023-08-16 12:55:42,315] Trial 177 finished with value: 0.623728392642893 and parameters: {'max_depth': 3, 'learning_rate': 0.038928272850611456, 'n_estimators': 499, 'subsample': 0.2590429414474657, 'colsample_bytree': 0.23060084918295357, 'reg_alpha': 0.9666495027979651, 'reg_lambda': 0.8531174512564871}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 773us/step\n",
      "[I 2023-08-16 12:55:43,863] Trial 190 finished with value: 0.6372431198548869 and parameters: {'max_depth': 4, 'learning_rate': 0.03954779566605264, 'n_estimators': 156, 'subsample': 0.23040699194953135, 'colsample_bytree': 0.45425550153071936, 'reg_alpha': 0.4224697197540733, 'reg_lambda': 0.8888135570020954}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 773us/step\n",
      "[I 2023-08-16 12:55:44,325] Trial 202 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 744us/step\n",
      "[I 2023-08-16 12:55:45,431] Trial 178 finished with value: 0.6099075545281829 and parameters: {'max_depth': 5, 'learning_rate': 0.031944015453303005, 'n_estimators': 498, 'subsample': 0.22537810085058352, 'colsample_bytree': 0.36977714448264415, 'reg_alpha': 0.9579196630738669, 'reg_lambda': 0.9447488099888672}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 831us/step\n",
      "[I 2023-08-16 12:55:46,410] Trial 189 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 799us/step\n",
      "[I 2023-08-16 12:55:46,728] Trial 205 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 947us/step\n",
      "[I 2023-08-16 12:55:47,723] Trial 204 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 815us/step\n",
      "[I 2023-08-16 12:55:47,845] Trial 206 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:55:49,126] Trial 208 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 673us/step\n",
      "[I 2023-08-16 12:55:49,693] Trial 209 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 866us/step\n",
      "[I 2023-08-16 12:55:49,851] Trial 198 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 969us/step\n",
      "[I 2023-08-16 12:55:49,988] Trial 199 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[I 2023-08-16 12:55:50,606] Trial 210 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 978us/step\n",
      "[I 2023-08-16 12:55:51,232] Trial 211 pruned. Trial was pruned at iteration 25.\n",
      "[I 2023-08-16 12:55:51,270] Trial 201 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "1/5 [=====>........................] - ETA: 0s[I 2023-08-16 12:55:51,350] Trial 212 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 724us/step\n",
      "[I 2023-08-16 12:55:51,966] Trial 213 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 885us/step\n",
      "[I 2023-08-16 12:55:52,521] Trial 214 pruned. Trial was pruned at iteration 25.\n",
      "[I 2023-08-16 12:55:52,549] Trial 215 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 825us/step\n",
      "[I 2023-08-16 12:55:52,832] Trial 217 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:55:53,392] Trial 218 pruned. Trial was pruned at iteration 25.\n",
      "[I 2023-08-16 12:55:53,404] Trial 203 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 760us/step\n",
      "5/5 [==============================] - 0s 836us/step\n",
      "[I 2023-08-16 12:55:53,965] Trial 219 pruned. Trial was pruned at iteration 25.\n",
      "[I 2023-08-16 12:55:54,015] Trial 220 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 909us/step\n",
      "[I 2023-08-16 12:55:54,232] Trial 221 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 845us/step\n",
      "[I 2023-08-16 12:55:55,015] Trial 222 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:55:55,120] Trial 224 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 862us/step\n",
      "[I 2023-08-16 12:55:55,450] Trial 226 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 843us/step\n",
      "[I 2023-08-16 12:55:55,662] Trial 225 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[I 2023-08-16 12:55:56,530] Trial 228 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 874us/step\n",
      "[I 2023-08-16 12:55:57,393] Trial 223 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:55:57,920] Trial 231 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 904us/step\n",
      "[I 2023-08-16 12:55:58,646] Trial 229 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 899us/step\n",
      "[I 2023-08-16 12:55:58,941] Trial 227 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 897us/step\n",
      "[I 2023-08-16 12:55:59,753] Trial 230 pruned. Trial was pruned at iteration 75.\n",
      "[I 2023-08-16 12:55:59,753] Trial 200 finished with value: 0.6569722202501929 and parameters: {'max_depth': 10, 'learning_rate': 0.039840852418799436, 'n_estimators': 491, 'subsample': 0.25730492084614404, 'colsample_bytree': 0.2525743990890124, 'reg_alpha': 0.6319702368446488, 'reg_lambda': 0.9706294317249512}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[I 2023-08-16 12:56:01,116] Trial 236 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 652us/step\n",
      "[I 2023-08-16 12:56:01,685] Trial 237 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 733us/step\n",
      "[I 2023-08-16 12:56:02,341] Trial 234 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 962us/step\n",
      "[I 2023-08-16 12:56:02,686] Trial 235 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:56:03,327] Trial 216 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 943us/step\n",
      "[I 2023-08-16 12:56:04,164] Trial 233 finished with value: 0.5839478798746452 and parameters: {'max_depth': 9, 'learning_rate': 0.07834056568891898, 'n_estimators': 166, 'subsample': 0.24688592369977513, 'colsample_bytree': 0.21701315547634198, 'reg_alpha': 0.7816694086176526, 'reg_lambda': 0.957417906787775}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 719us/step\n",
      "[I 2023-08-16 12:56:04,256] Trial 240 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:56:04,493] Trial 242 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 738us/step\n",
      "[I 2023-08-16 12:56:04,680] Trial 239 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 705us/step\n",
      "[I 2023-08-16 12:56:04,936] Trial 207 finished with value: 0.658935955950077 and parameters: {'max_depth': 10, 'learning_rate': 0.04594222726940078, 'n_estimators': 487, 'subsample': 0.2754126284066251, 'colsample_bytree': 0.25637834126651504, 'reg_alpha': 0.9103933321064714, 'reg_lambda': 0.971542061138131}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:56:05,670] Trial 245 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 821us/step\n",
      "[I 2023-08-16 12:56:06,738] Trial 248 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 771us/step\n",
      "[I 2023-08-16 12:56:08,200] Trial 249 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 835us/step\n",
      "[I 2023-08-16 12:56:09,368] Trial 250 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 814us/step\n",
      "[I 2023-08-16 12:56:10,644] Trial 251 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 970us/step\n",
      "[I 2023-08-16 12:56:11,429] Trial 241 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:56:12,272] Trial 252 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 878us/step\n",
      "[I 2023-08-16 12:56:13,108] Trial 253 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 891us/step\n",
      "[I 2023-08-16 12:56:13,224] Trial 254 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 920us/step\n",
      "[I 2023-08-16 12:56:14,181] Trial 247 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 653us/step\n",
      "[I 2023-08-16 12:56:14,262] Trial 244 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 959us/step\n",
      "[I 2023-08-16 12:56:14,492] Trial 246 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:56:14,613] Trial 256 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:56:14,790] Trial 255 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 762us/step\n",
      "[I 2023-08-16 12:56:15,850] Trial 232 finished with value: 0.5984475821982701 and parameters: {'max_depth': 8, 'learning_rate': 0.03171241480636027, 'n_estimators': 460, 'subsample': 0.24576239625998067, 'colsample_bytree': 0.21671905133332858, 'reg_alpha': 0.5355880625663504, 'reg_lambda': 0.9527243782119946}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 813us/step\n",
      "[I 2023-08-16 12:56:16,269] Trial 257 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 891us/step\n",
      "[I 2023-08-16 12:56:16,517] Trial 259 pruned. Trial was pruned at iteration 25.\n",
      "[I 2023-08-16 12:56:16,553] Trial 261 pruned. Trial was pruned at iteration 25.\n",
      "[I 2023-08-16 12:56:16,601] Trial 260 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:56:17,239] Trial 262 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 840us/step\n",
      "[I 2023-08-16 12:56:17,695] Trial 263 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 799us/step\n",
      "[I 2023-08-16 12:56:17,913] Trial 264 pruned. Trial was pruned at iteration 25.\n",
      "[I 2023-08-16 12:56:17,955] Trial 265 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[I 2023-08-16 12:56:18,276] Trial 266 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 757us/step\n",
      "[I 2023-08-16 12:56:18,851] Trial 267 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 849us/step\n",
      "[I 2023-08-16 12:56:19,497] Trial 268 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 753us/step\n",
      "[I 2023-08-16 12:56:19,714] Trial 270 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:56:19,900] Trial 271 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 899us/step\n",
      "[I 2023-08-16 12:56:20,019] Trial 269 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:56:20,780] Trial 272 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 930us/step\n",
      "[I 2023-08-16 12:56:20,930] Trial 274 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:56:21,259] Trial 273 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 779us/step\n",
      "[I 2023-08-16 12:56:21,749] Trial 275 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:56:22,027] Trial 276 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 705us/step\n",
      "[I 2023-08-16 12:56:22,625] Trial 243 finished with value: 0.6622355120679768 and parameters: {'max_depth': 10, 'learning_rate': 0.044257918263519, 'n_estimators': 481, 'subsample': 0.21645792238077055, 'colsample_bytree': 0.2625297371644787, 'reg_alpha': 0.46159500123336483, 'reg_lambda': 0.6249459031502306}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 731us/step\n",
      "[I 2023-08-16 12:56:22,825] Trial 278 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 926us/step\n",
      "[I 2023-08-16 12:56:23,596] Trial 238 finished with value: 0.658970068460596 and parameters: {'max_depth': 10, 'learning_rate': 0.03225767072242611, 'n_estimators': 500, 'subsample': 0.29661721883039516, 'colsample_bytree': 0.21899678483247215, 'reg_alpha': 0.4658399796327679, 'reg_lambda': 0.9603963088939702}. Best is trial 4 with value: 0.7180449014905719.\n",
      "5/5 [==============================] - 0s 722us/step\n",
      "[I 2023-08-16 12:56:24,193] Trial 283 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 869us/step\n",
      "[I 2023-08-16 12:56:24,455] Trial 258 pruned. Trial was pruned at iteration 225.\n",
      "5/5 [==============================] - 0s 709us/step\n",
      "[I 2023-08-16 12:56:25,230] Trial 284 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:56:25,383] Trial 285 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:56:25,690] Trial 280 pruned. Trial was pruned at iteration 75.\n",
      "[I 2023-08-16 12:56:25,754] Trial 286 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "[I 2023-08-16 12:56:25,796] Trial 282 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[I 2023-08-16 12:56:25,970] Trial 281 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 741us/step\n",
      "[I 2023-08-16 12:56:26,754] Trial 287 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 871us/step\n",
      "[I 2023-08-16 12:56:26,979] Trial 288 pruned. Trial was pruned at iteration 25.\n",
      "[I 2023-08-16 12:56:27,038] Trial 291 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "5/5 [==============================] - 0s 970us/step\n",
      "[I 2023-08-16 12:56:27,215] Trial 292 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 799us/step\n",
      "[I 2023-08-16 12:56:28,256] Trial 294 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 825us/step\n",
      "[I 2023-08-16 12:56:28,554] Trial 293 pruned. Trial was pruned at iteration 25.\n",
      "5/5 [==============================] - 0s 878us/step\n",
      "[I 2023-08-16 12:56:28,668] Trial 296 pruned. Trial was pruned at iteration 25.\n",
      "[I 2023-08-16 12:56:28,673] Trial 289 pruned. Trial was pruned at iteration 75.\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "[I 2023-08-16 12:56:29,121] Trial 290 pruned. Trial was pruned at iteration 75.\n",
      "[I 2023-08-16 12:56:29,533] Trial 297 pruned. Trial was pruned at iteration 25.\n",
      "[I 2023-08-16 12:56:29,558] Trial 298 pruned. Trial was pruned at iteration 25.\n",
      "[I 2023-08-16 12:56:29,582] Trial 279 pruned. Trial was pruned at iteration 225.\n",
      "[I 2023-08-16 12:56:29,591] Trial 299 pruned. Trial was pruned at iteration 25.\n",
      "[I 2023-08-16 12:56:29,812] Trial 295 pruned. Trial was pruned at iteration 75.\n",
      "[I 2023-08-16 12:56:30,476] Trial 277 finished with value: 0.6468248958266102 and parameters: {'max_depth': 4, 'learning_rate': 0.07011978654274051, 'n_estimators': 479, 'subsample': 0.2389404170304951, 'colsample_bytree': 0.2325832341610155, 'reg_alpha': 0.5701576170355966, 'reg_lambda': 0.8935928727631026}. Best is trial 4 with value: 0.7180449014905719.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def objective(trial):\n",
    "    # Sample hyperparameters for the meta-learner\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 1, 10)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.1)\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 500)\n",
    "    subsample = trial.suggest_float(\"subsample\", 0.2, 1.0)\n",
    "    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.2, 1.0)\n",
    "    reg_alpha = trial.suggest_float(\"reg_alpha\", 0.0, 1.0)\n",
    "    reg_lambda = trial.suggest_float(\"reg_lambda\", 0.0, 1.0)\n",
    "    \n",
    "    # Train the meta-learner on the predicted probabilities\n",
    "    meta_learner = XGBClassifier(\n",
    "        random_state=42,\n",
    "        eval_metric='merror',\n",
    "        objective='multi:softmax',\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators,\n",
    "        subsample = subsample,\n",
    "        reg_alpha = reg_alpha,\n",
    "        reg_lambda = reg_lambda,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        callbacks=[optuna.integration.XGBoostPruningCallback(trial, observation_key=\"validation_0-merror\")]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # Get prediction for the val and test sets from learners\n",
    "    #Val Set\n",
    "    X_meta_val = np.concatenate([y_proba_dlv,y_proba_dlv2], axis=1)\n",
    "\n",
    "    #Test Set\n",
    "    y_proba_dlt = loaded_model.predict(X_test_some)\n",
    "    X_meta_test = np.concatenate([y_proba_dlt,y_proba_dlt2], axis=1)\n",
    "    #Build Meta Learner\n",
    "    meta_learner.fit(X_meta_val, y_val_some,eval_set = [(X_meta_test,y_test_some)],verbose = 0)\n",
    "    y_pred_meta = meta_learner.predict(X_meta_test)\n",
    "    \n",
    "    # Calculate and return the accuracy as the objective\n",
    "    f1 = f1_score(y_test_some,y_pred_meta,average = 'weighted')\n",
    "    return f1\n",
    "\n",
    "# Run the optimization using Hyperband pruning\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    pruner=HyperbandPruner(min_resource=25)\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=300,n_jobs = -1, show_progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 7,\n",
       " 'learning_rate': 0.037914583026431935,\n",
       " 'n_estimators': 146,\n",
       " 'subsample': 0.5736373943198284,\n",
       " 'colsample_bytree': 0.8749771610457713,\n",
       " 'reg_alpha': 0.45261287773891445,\n",
       " 'reg_lambda': 0.8360368643167558}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_meta_params = {'max_depth': 3,\n",
    " 'learning_rate': 0.04097970899174354,\n",
    " 'n_estimators': 148,\n",
    " 'subsample': 0.5813429245642656,\n",
    " 'colsample_bytree': 0.5029078289354505,\n",
    " 'reg_alpha': 0.23997676193839024,\n",
    " 'reg_lambda': 0.7623265939843972}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-merror:0.43671\n",
      "[2]\tvalidation_0-merror:0.37975\n",
      "[4]\tvalidation_0-merror:0.36709\n",
      "[6]\tvalidation_0-merror:0.32911\n",
      "[8]\tvalidation_0-merror:0.31646\n",
      "[10]\tvalidation_0-merror:0.31646\n",
      "[12]\tvalidation_0-merror:0.29747\n",
      "[14]\tvalidation_0-merror:0.27848\n",
      "[16]\tvalidation_0-merror:0.28481\n",
      "[18]\tvalidation_0-merror:0.28481\n",
      "[20]\tvalidation_0-merror:0.28481\n",
      "[22]\tvalidation_0-merror:0.27215\n",
      "[24]\tvalidation_0-merror:0.26582\n",
      "[26]\tvalidation_0-merror:0.26582\n",
      "[28]\tvalidation_0-merror:0.25949\n",
      "[30]\tvalidation_0-merror:0.26582\n",
      "[32]\tvalidation_0-merror:0.26582\n",
      "[34]\tvalidation_0-merror:0.26582\n",
      "[36]\tvalidation_0-merror:0.26582\n",
      "[38]\tvalidation_0-merror:0.27215\n",
      "[40]\tvalidation_0-merror:0.27215\n",
      "[42]\tvalidation_0-merror:0.26582\n",
      "[44]\tvalidation_0-merror:0.26582\n",
      "[46]\tvalidation_0-merror:0.27848\n",
      "[48]\tvalidation_0-merror:0.27215\n",
      "[50]\tvalidation_0-merror:0.27215\n",
      "[52]\tvalidation_0-merror:0.27215\n",
      "[54]\tvalidation_0-merror:0.27215\n",
      "[56]\tvalidation_0-merror:0.26582\n",
      "[58]\tvalidation_0-merror:0.27848\n",
      "[60]\tvalidation_0-merror:0.27848\n",
      "[62]\tvalidation_0-merror:0.27848\n",
      "[64]\tvalidation_0-merror:0.27848\n",
      "[66]\tvalidation_0-merror:0.27848\n",
      "[68]\tvalidation_0-merror:0.27848\n",
      "[70]\tvalidation_0-merror:0.28481\n",
      "[72]\tvalidation_0-merror:0.28481\n",
      "[74]\tvalidation_0-merror:0.28481\n",
      "[76]\tvalidation_0-merror:0.28481\n",
      "[78]\tvalidation_0-merror:0.28481\n",
      "[80]\tvalidation_0-merror:0.27215\n",
      "[82]\tvalidation_0-merror:0.27215\n",
      "[84]\tvalidation_0-merror:0.27848\n",
      "[86]\tvalidation_0-merror:0.27215\n",
      "[88]\tvalidation_0-merror:0.27215\n",
      "[90]\tvalidation_0-merror:0.27215\n",
      "[92]\tvalidation_0-merror:0.27215\n",
      "[94]\tvalidation_0-merror:0.27848\n",
      "[96]\tvalidation_0-merror:0.28481\n",
      "[98]\tvalidation_0-merror:0.28481\n",
      "[100]\tvalidation_0-merror:0.28481\n",
      "[102]\tvalidation_0-merror:0.27848\n",
      "[104]\tvalidation_0-merror:0.28481\n",
      "[106]\tvalidation_0-merror:0.27848\n",
      "[108]\tvalidation_0-merror:0.27848\n",
      "[110]\tvalidation_0-merror:0.27848\n",
      "[112]\tvalidation_0-merror:0.27848\n",
      "[114]\tvalidation_0-merror:0.27848\n",
      "[116]\tvalidation_0-merror:0.27848\n",
      "[118]\tvalidation_0-merror:0.27848\n",
      "[120]\tvalidation_0-merror:0.27848\n",
      "[122]\tvalidation_0-merror:0.27848\n",
      "[124]\tvalidation_0-merror:0.27215\n",
      "[126]\tvalidation_0-merror:0.27215\n",
      "[128]\tvalidation_0-merror:0.27215\n",
      "[130]\tvalidation_0-merror:0.27215\n",
      "[132]\tvalidation_0-merror:0.27215\n",
      "[134]\tvalidation_0-merror:0.26582\n",
      "[136]\tvalidation_0-merror:0.26582\n",
      "[138]\tvalidation_0-merror:0.26582\n",
      "[140]\tvalidation_0-merror:0.26582\n",
      "[142]\tvalidation_0-merror:0.26582\n",
      "[144]\tvalidation_0-merror:0.26582\n",
      "[146]\tvalidation_0-merror:0.25949\n",
      "[147]\tvalidation_0-merror:0.25949\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "0.7266596448109285\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    battery issue       0.67      0.80      0.73         5\n",
      "             bmis       1.00      0.50      0.67         2\n",
      "      cable issue       0.68      0.88      0.77        17\n",
      "data access issue       0.61      0.73      0.67        15\n",
      "decision accuracy       0.00      0.00      0.00         5\n",
      "    display issue       0.50      0.50      0.50         2\n",
      "        fan issue       0.60      0.86      0.71         7\n",
      "          freezes       0.71      0.83      0.77         6\n",
      "   hardware issue       0.33      0.33      0.33         6\n",
      "       no details       1.00      0.85      0.92        13\n",
      "      power issue       0.75      0.75      0.75         4\n",
      "        shuts off       0.33      0.25      0.29         4\n",
      "   software issue       0.00      0.00      0.00         4\n",
      "temp sensor error       1.00      0.50      0.67         2\n",
      "    testing issue       0.50      0.33      0.40         3\n",
      "    update issues       0.91      0.95      0.93        41\n",
      "         vin scan       0.78      0.88      0.82         8\n",
      "      wifi issues       1.00      0.64      0.78        14\n",
      "\n",
      "         accuracy                           0.74       158\n",
      "        macro avg       0.63      0.59      0.59       158\n",
      "     weighted avg       0.73      0.74      0.73       158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the meta-learner on the predicted probabilities\n",
    "meta_learner = XGBClassifier(\n",
    "    random_state=42,\n",
    "    eval_metric='merror',\n",
    "    objective='multi:softmax',**best_meta_params)\n",
    "    \n",
    "meta_learner.fit(X_meta, y_val_some,eval_set = [(X_meta_test,y_test_some)],verbose = 2)\n",
    "    \n",
    "# Predict with the meta-learner on the test set\n",
    "y_proba_dlt = loaded_model.predict(X_test_some)\n",
    "    \n",
    "X_meta_test = np.concatenate([y_proba_dlt,y_proba_dlt2], axis=1)\n",
    "y_pred_meta = meta_learner.predict(X_meta_test)\n",
    "    \n",
    "# Calculate and return the accuracy as the objective\n",
    "f1 = f1_score(y_test_some,y_pred_meta,average = 'weighted')\n",
    "print(f1)\n",
    "print(classification_report(y_test_some,y_pred_meta,target_names = le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, deep learning proved to be the best performing classifier. Using the predicted probabilies of the two best deep learning models to train a third xgboost model (meta learner) did not reproduce any imporvements in results. Other methods of stacking have not been fully explored, so there may still be other methods of improving model performance without additional training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myworkenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
